{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-24T12:01:21.407444Z","iopub.status.busy":"2024-08-24T12:01:21.407010Z","iopub.status.idle":"2024-08-24T12:01:29.827271Z","shell.execute_reply":"2024-08-24T12:01:29.826059Z","shell.execute_reply.started":"2024-08-24T12:01:21.407404Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 1\n","\n","import numpy as np\n","import os\n","import pickle\n","import time\n","import timeit\n","import json\n","\n","os.environ[\"DGLBACKEND\"] = \"pytorch\"\n","\n","import dgl\n","from dgl import from_networkx, node_subgraph\n","\n","import torch as th\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.utils import class_weight\n","\n","import src.models as models\n","# from src.models import GRAPHSAGE, GAT, GCN\n","from src.dataset.dataset_info import datasets\n","from src.plot_confusion_matrix import plot_confusion_matrix\n","from src.calculate_FPR_FNR import calculate_FPR_FNR_with_global\n","\n","# datasets = {dataset.name: dataset for dataset in datasets_list}\n","\n","%aimport src.models\n","\n","num_epochs = 100\n","batch_size = 16\n","learning_rate = 0.001\n","LAMBD_1 = 0.0001\n","LAMBD_2 = 0.001\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["name = \"cic_ids_2017_5_percent\"\n","# name = \"cic_ton_iot_5_percent\"\n","# name = \"cic_ton_iot\"\n","# name = \"cic_ids_2017\"\n","# name = \"nf_bot_iot\"\n","# name = \"edge_iiot\"\n","# name = \"nf_cse_cic_ids2018\"\n","# name = \"nf_bot_iotv2\"\n","# name = \"nf_uq_nids\"\n","# name = \"x_iiot\"\n","# name = \"cic_ton_iot_modified\"\n","# name = \"nf_ton_iotv2_modified\"\n","# name = \"ccd_inid_modified\"\n","# name = \"nf_uq_nids_modified\"\n","\n","\n","with_centralities = False\n","\n","validate = True\n","validate_epoch = 1\n","\n","using_masking = False\n","masked_class = 2\n","\n","multi_class = True\n","\n","use_port_in_address = True\n","generated_ips = False\n","\n","graph_type = \"line\"\n","\n","window_size= 2000\n","\n","sort_timestamp = False\n","\n","dataset = datasets[name]\n","\n","dataset_folder = os.path.join(\"datasets\", name)\n","dataset_folder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["g_type = f\"line_graph_{window_size}\"\n","\n","if multi_class:\n","    g_type += \"__multi_class\"\n","    \n","# if k_fold:\n","#     g_type += f\"__{k_fold}_fold\"\n","    \n","if use_port_in_address:\n","    g_type += \"__ports\"\n","    \n","if generated_ips:\n","    g_type += \"__generated_ips\"\n","    \n","if sort_timestamp:\n","    g_type += \"__sorted\"\n","else:\n","    g_type += \"__unsorted\"\n","    \n","graphs_folder = os.path.join(dataset_folder, g_type)\n","graphs_folder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["number_neighbors = [25, 10]\n","# number_neighbors = None\n","num_layers=3\n","ndim_out = [128, 256, 256]\n","aggregation=\"mean\"\n","activation=F.relu\n","dropout=0.2\n","\n","my_models = [\n","    models.LineGraphModel(\"gcn\", models.GCN, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout),\n","    models.LineGraphModel(\"graph_sage\", models.GRAPHSAGE, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, aggregator_type=aggregation),\n","    models.LineGraphModel(\"gat\", models.GAT, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout),\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_final = {}\n","\n","results_final[\"name\"] = name\n","results_final[\"g_type\"] = g_type\n","results_final[\"configuration\"] = {\n","    \"num_epochs\": num_epochs,\n","    \"multi_class\": multi_class,\n","    \"batch_size\": batch_size,\n","    \"learning_rate\": learning_rate,\n","    \"num_neighbors\": number_neighbors,\n","    \"with_centralities\": with_centralities,\n","    \"using_masking\": using_masking,\n","    \"masked_class_num\": masked_class,\n","    # \"early_stopping\": early_stopping,\n","    # \"pca\": pca,\n","    # \"digraph_centralities\": digraph_centralities,\n","    # \"multi_graph_centralities\": multi_graph_centralities,\n","    # \"learning_rate\": learning_rate,\n","    # \"LAMBD_1\": LAMBD_1,\n","    # \"LAMBD_2\": LAMBD_2,\n","    # \"cfg\": OmegaConf.to_container(cfg)\n","}\n","\n","results_final[\"accuracy\"] = {}\n","results_final[\"f1_score\"] = {}\n","results_final[\"FPR\"] = {}\n","results_final[\"FNR\"] = {}\n","results_final[\"time_elapsed\"] = {}\n","results_final[\"val_accuracy\"] = {}\n","results_final[\"val_precision\"] = {}\n","results_final[\"val_recall\"] = {}\n","results_final[\"val_f1\"] = {}\n","results_final[\"val_FPR\"] = {}\n","results_final[\"val_FNR\"] = {}\n","\n","for m in my_models:\n","    results_final[m.model_name] = {}\n","    results_final[\"accuracy\"][m.model_name] = []\n","    results_final[\"time_elapsed\"][m.model_name] = []\n","    results_final[\"val_accuracy\"][m.model_name] = []\n","    results_final[\"val_precision\"][m.model_name] = []\n","    results_final[\"val_recall\"][m.model_name] = []\n","    results_final[\"val_f1\"][m.model_name] = []\n","    results_final[\"val_FPR\"][m.model_name] = []\n","    results_final[\"val_FNR\"][m.model_name] = []\n","\n","results_final"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dtime = time.strftime(\"%Y%m%d-%H%M%S\")\n","dtime"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_folder_path = \"results\"\n","results_folder_path1 = os.path.join(results_folder_path, name)\n","results_folder_path2 = os.path.join(results_folder_path1, g_type)\n","folder_path = os.path.join(results_folder_path2, dtime)\n","confusion_matrices_path = os.path.join(folder_path, \"confusion_matrices\")\n","os.makedirs(confusion_matrices_path, exist_ok=True)\n","# os.makedirs(confusion_matrices_path, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labels = [\"Normal\", \"Attack\"]\n","num_classes = 2\n","if multi_class:\n","    with open(os.path.join(dataset_folder, \"labels_names.pkl\"), \"rb\") as f:\n","        labels_names = pickle.load(f)\n","    labels_mapping = labels_names[0]\n","    # labels = labels_names[1]\n","    labels = list(labels_mapping.values())\n","    num_classes = len(labels)\n","labels, num_classes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if using_masking:\n","    results_final[\"configuration\"][\"masked_class_name\"] = str(labels[masked_class])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_folder_path = None\n","dataset_folder_path_train = os.path.join(graphs_folder, \"training\", \"graphs\")\n","dataset_folder_path_val = os.path.join(graphs_folder, \"validation\", \"graphs\")\n","dataset_folder_path_test = os.path.join(graphs_folder, \"testing\", \"graphs\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["node_attrs = ['h', dataset.label_col, dataset.class_num_col]\n","# node_attrs = ['h', dataset.label_col, dataset.class_num_col, \"index\"]\n","# read training, validation, and testing graphs\n","if dataset_folder_path:\n","    graphs = []\n","    for file in os.listdir(dataset_folder_path):\n","        # print(f\"==>> file: {os.path.join(dataset_folder_path_train, file)}\")\n","        with open(os.path.join(dataset_folder_path, file), \"rb\") as f:\n","            G = pickle.load(f)\n","            # print(list(G.nodes(data=True))[0])\n","            G = from_networkx(G,node_attrs=node_attrs)\n","            node_label = G.ndata[dataset.label_col]\n","            # if len(node_label.unique()) > 1:\n","            #     print(f\"==>> node_label.unique(): {len(node_label.unique())}\")\n","                \n","            graphs.append(G)\n","\n","            # break\n","            \n","    training_graphs, testing_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\n","    len(training_graphs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if dataset_folder_path_train:\n","    training_graphs = []\n","    training_labels = []\n","    for file in os.listdir(dataset_folder_path_train):\n","        with open(os.path.join(dataset_folder_path_train, file), \"rb\") as f:\n","            G = pickle.load(f)\n","            # print(list(G.nodes(data=True))[0])\n","            G = from_networkx(G,node_attrs=node_attrs)\n","            if multi_class:\n","                node_labels = G.ndata[dataset.class_num_col]\n","            else:\n","                node_labels = G.ndata[dataset.label_col]\n","                \n","            if using_masking:\n","                training_mask = G.ndata[dataset.class_num_col] != masked_class\n","                G = node_subgraph(G, training_mask)\n","            training_graphs.append(G)\n","            training_labels.append(node_labels)\n","    len(training_graphs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if dataset_folder_path_val:\n","    validation_graphs = []\n","    for file in os.listdir(dataset_folder_path_val):\n","        with open(os.path.join(dataset_folder_path_val, file), \"rb\") as f:\n","            G = pickle.load(f)\n","            G = from_networkx(G,node_attrs=node_attrs)\n","            validation_graphs.append(G)\n","    len(validation_graphs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if dataset_folder_path_test:\n","    testing_graphs = []\n","    for file in os.listdir(dataset_folder_path_test):\n","        with open(os.path.join(dataset_folder_path_test, file), \"rb\") as f:\n","            G = pickle.load(f)\n","            G = from_networkx(G,node_attrs=node_attrs)\n","            testing_graphs.append(G)\n","    len(testing_graphs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["G0 = training_graphs[0]\n","num_features = G.ndata['h'].shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["concat_training_labels = th.cat(training_labels).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class_weights = class_weight.compute_class_weight('balanced',\n","                                                classes=np.unique(concat_training_labels),\n","                                                y=concat_training_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if using_masking:\n","    class_weights=np.insert(class_weights, masked_class, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class_weights = th.FloatTensor(class_weights)\n","\n","criterion = nn.CrossEntropyLoss(weight=class_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def compute_accuracy(pred, labels):\n","    # return (pred == labels).float().mean().item()\n","    correct = 0\n","    total = len(labels)\n","    # Count correct predictions\n","    correct = np.sum(np.array(pred) == np.array(labels))\n","\n","    # Compute accuracy\n","    accuracy = correct / total if total > 0 else 0\n","    return accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class GraphDataset(th.utils.data.Dataset):\n","    def __init__(self, graphs):\n","        self.graphs = graphs\n","\n","    def __len__(self):\n","        return len(self.graphs)\n","\n","    def __getitem__(self, idx):\n","        return self.graphs[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset = GraphDataset(training_graphs)\n","val_dataset = GraphDataset(validation_graphs)\n","test_dataset = GraphDataset(testing_graphs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=dgl.batch)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=dgl.batch)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=dgl.batch)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate_model(model, loader, labels, results_f, epoch, model_name):\n","    start_time = timeit.default_timer()\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    \n","    with th.no_grad():\n","        for batched_graph in loader:\n","            features = batched_graph.ndata['h']\n","            labels_batch = batched_graph.ndata[dataset.class_num_col if multi_class else dataset.label_col]\n","            logits = model(batched_graph, features)\n","            preds = th.argmax(logits, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels_batch.cpu().numpy())\n","    \n","    elapsed = timeit.default_timer() - start_time\n","    # print(f\"Time for validation: {elapsed:.4f}\")\n","    # Compute metrics\n","    actual = all_labels\n","    test_pred = all_preds\n","    \n","    if multi_class:\n","        actual = np.vectorize(labels_names[0].get)(actual)\n","        test_pred = np.vectorize(labels_names[0].get)(test_pred)\n","    else:\n","        actual = [\"Normal\" if i == 0 else \"Attack\" for i in actual]\n","        test_pred = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred]\n","\n","    cr = classification_report(actual, test_pred, digits=4, output_dict=True, zero_division=0)\n","    \n","    val_acc = cr[\"accuracy\"]\n","    val_precision = cr['weighted avg']['precision']\n","    val_recall = cr['weighted avg']['recall']\n","    val_f1 = cr['weighted avg']['f1-score']\n","    cm = confusion_matrix(actual, test_pred, labels=labels)\n","\n","    results_fpr_fnr = calculate_FPR_FNR_with_global(cm)\n","    \n","    # Log metrics\n","    results_f[\"val_accuracy\"][model_name].append(val_acc)\n","    results_f[\"val_precision\"][model_name].append(val_precision)\n","    results_f[\"val_recall\"][model_name].append(val_recall)\n","    results_f[\"val_f1\"][model_name].append(val_f1)\n","    results_f[\"val_FPR\"][model_name].append(results_fpr_fnr[\"global\"][\"FPR\"])\n","    results_f[\"val_FNR\"][model_name].append(results_fpr_fnr[\"global\"][\"FNR\"])\n","\n","    return val_acc, elapsed\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_model(line_graph_model: models.LineGraphModel, train_loader, val_loader, num_epochs, lr):\n","    \n","    if line_graph_model.model_class == models.GRAPHSAGE:\n","        line_graph_model.training_model = line_graph_model.model_class(num_features, ndim_out=line_graph_model.ndim_out, aggregator_type = line_graph_model.aggregator_type, n_classes=num_classes)\n","        line_graph_model.best_model = line_graph_model.model_class(num_features, ndim_out=line_graph_model.ndim_out, aggregator_type = line_graph_model.aggregator_type, n_classes=num_classes)\n","    else:\n","        line_graph_model.training_model = line_graph_model.model_class(num_features, ndim_out=line_graph_model.ndim_out, n_classes=num_classes)\n","        line_graph_model.best_model = line_graph_model.model_class(num_features, ndim_out=line_graph_model.ndim_out, n_classes=num_classes)\n","        \n","    optimizer = th.optim.Adam(line_graph_model.training_model.parameters(), lr=lr)\n","    loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n","    # if multi_class:\n","    #     loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n","    # else:\n","    #     loss_fn = nn.BCEWithLogitsLoss(weight=class_weights)\n","    best_val_acc = 0\n","\n","    print(\"================================\")\n","    print(\"================================\")\n","    print(f\"Training Model: {line_graph_model.model_name}\")\n","    \n","    for epoch in range(num_epochs):\n","        \n","        all_training_preds = []\n","        all_training_labels = []\n","    \n","        line_graph_model.training_model.train()\n","        for batched_graph in train_loader:\n","            features = batched_graph.ndata['h']\n","            actual_labels = batched_graph.ndata[dataset.class_num_col if multi_class else dataset.label_col]\n","\n","            logits = line_graph_model.training_model(batched_graph, features)\n","            loss = loss_fn(logits, actual_labels)\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            preds = th.argmax(logits, dim=-1)\n","            all_training_preds.extend(preds.cpu().numpy())\n","            all_training_labels.extend(actual_labels.cpu().numpy())\n","        \n","        pred = all_training_preds\n","        actual_labels = all_training_labels\n","        train_acc = compute_accuracy(pred, actual_labels)\n","        # print(\"Model: {} -- Epoch: {} -- Training acc: {:.5f}\".format(line_graph_model.model_name, epoch, compute_accuracy(pred, actual_labels)))\n","        print(f\"Model: {line_graph_model.model_name} -- Epoch: {epoch} -- Training acc: {train_acc:.4f}\")\n","        # Validation step\n","        val_acc, elapsed = evaluate_model(\n","            line_graph_model.training_model, \n","            val_loader, \n","            labels, \n","            results_final, \n","            epoch, \n","            model_name=line_graph_model.model_name\n","        )\n","        print(f\"Model: {line_graph_model.model_name} -- Epoch: {epoch} -- Training acc: {val_acc:.4f}\")\n","        print(f\"Time for validation: {elapsed:.4f}\")\n","\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            best_model_state = line_graph_model.training_model.state_dict().copy()\n","            \n","    line_graph_model.best_model.load_state_dict(best_model_state)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_model(model, loader, labels, model_name, results_f):\n","    print(\"=======================\")\n","    print(f\"testing model: {model_name}\")\n","\n","    start_time = timeit.default_timer()\n","    \n","    # Run evaluation\n","    all_preds = []\n","    all_labels = []\n","    \n","    model.eval()\n","    with th.no_grad():\n","        for batched_graph in loader:\n","            features = batched_graph.ndata['h']\n","            labels_batch = batched_graph.ndata[dataset.class_num_col if multi_class else dataset.label_col]  # Adjust to 'class' for multi-class\n","            logits = model(batched_graph, features)\n","            preds = th.argmax(logits, dim=1)\n","            \n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels_batch.cpu().numpy())\n","    \n","    elapsed = timeit.default_timer() - start_time\n","    # Compute metrics\n","    actual = all_labels\n","    test_pred = all_preds\n","    \n","    \n","    if multi_class:\n","        actual = np.vectorize(labels_names[0].get)(actual)\n","        test_pred = np.vectorize(labels_names[0].get)(test_pred)\n","    else:\n","        actual = [\"Normal\" if i == 0 else \"Attack\" for i in actual]\n","        test_pred = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred]\n","\n","    cr = classification_report(actual, test_pred, digits=4, output_dict=True, zero_division=0)\n","\n","    cm = confusion_matrix(actual, test_pred, labels=labels)\n","    results_fpr_fnr = calculate_FPR_FNR_with_global(cm)\n","    \n","\n","    # Log metrics\n","    results_f[model_name][\"elapsed\"] = elapsed\n","    results_f[model_name][\"classification_report\"] = cr\n","    results_f[model_name][\"results_fpr_fnr\"] = results_fpr_fnr\n","    results_f[\"accuracy\"][model_name] = cr[\"accuracy\"]\n","    results_f[\"f1_score\"][model_name] = cr['weighted avg']['f1-score']\n","    results_f[\"FPR\"][model_name] = results_fpr_fnr[\"global\"][\"FPR\"]\n","    results_f[\"FNR\"][model_name] = results_fpr_fnr[\"global\"][\"FNR\"]\n","    results_f[\"time_elapsed\"][model_name] = elapsed\n","\n","\n","    print(classification_report(actual, test_pred, digits=4, zero_division=0))\n","    \n","    return cm\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Training GNN models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %autoreload"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NumpyEncoder(json.JSONEncoder):\n","    def default(self, obj):\n","        if isinstance(obj, np.integer):\n","            return int(obj)\n","        elif isinstance(obj, np.floating):\n","            return float(obj)\n","        elif isinstance(obj, np.ndarray):\n","            return obj.tolist()\n","        return super(NumpyEncoder, self).default(obj)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for m in my_models:\n","    train_model(m, train_loader, val_loader, num_epochs, learning_rate)\n","    # cm = test_model(m, G_test, test_labels, results_final, labels)\n","    cm = test_model(m.best_model, test_loader, labels, m.model_name, results_final)\n","    plot_confusion_matrix(cm=cm,\n","                          normalize=False,\n","                          target_names=labels,\n","                          title=\"Confusion Matrix\",\n","                          file_path=f\"{confusion_matrices_path}/{m.model_name}.png\")\n","    filename = (folder_path + '/results.json'.format(dtime))\n","    outfile = open(filename, 'w')\n","    outfile.writelines(json.dumps(results_final, cls=NumpyEncoder))\n","    outfile.close()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4775518,"sourceId":8089266,"sourceType":"datasetVersion"},{"datasetId":4775527,"sourceId":8089281,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
