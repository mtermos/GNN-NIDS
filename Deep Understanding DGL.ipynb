{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Understanding DGL: A Deep Dive**\n",
    "## **Introduction**\n",
    "In this notebook, I am diving deep into how the **Deep Graph Library (DGL)** works, particularly focusing on the `update_all` function. This function is a key operation in DGL that enables efficient **message passing** and **feature aggregation** in graph neural networks (GNNs).\n",
    "\n",
    "In addition to `local_scope()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `update_all` Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Simple graph with float data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import dgl.function as fn\n",
    "\n",
    "# Step 1: Create a graph (with multi-edges)\n",
    "g = dgl.graph(([0, 0, 2, 3, 3], [1, 1, 1, 2, 2]))  # Multi-edges exist (0→1 and 3→2)\n",
    "\n",
    "# Step 2: Assign node features\n",
    "g.ndata['h'] = torch.tensor([1.0, 0.0, 2.0, 3.0])  # Node feature\n",
    "g.ndata['nid'] = torch.tensor([0, 1, 2, 3])  # Node IDs\n",
    "\n",
    "# Step 3: Assign edge features\n",
    "g.edata['weight'] = torch.tensor([0.5, 1.5, 1.0, 1.5, 2.0])  # Edge weights\n",
    "g.edata['id'] = torch.tensor([0, 1, 2, 3, 4])  # Edge IDs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages on edges (m):\n",
      "tensor([0.5000, 1.5000, 2.0000, 4.5000, 6.0000])\n",
      "\n",
      "Updated node features after aggregation (h_neigh):\n",
      "tensor([0.0000, 1.3333, 5.2500, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Define a message function (using edge weight)\n",
    "def message_func(edges):\n",
    "    msg = edges.src['h'] * edges.data['weight']  # Compute message\n",
    "    g.edata['m'] = msg  # Manually store the message\n",
    "    return {'m': msg}  # Also return for update_all\n",
    "\n",
    "# Step 5: Apply `update_all` with mean aggregation\n",
    "g.update_all(message_func, fn.mean('m', 'h_neigh'))\n",
    "\n",
    "# Print results\n",
    "print(\"Messages on edges (m):\")\n",
    "print(g.edata['m'])  # Edge messages before aggregation\n",
    "\n",
    "print(\"\\nUpdated node features after aggregation (h_neigh):\")\n",
    "print(g.ndata['h_neigh'])  # Aggregated values at nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the explanation of the results:\n",
    "\n",
    "| Edge | Source → Destination | Source h | Weight | Message (m = h * weight) |\n",
    "|------|----------------------|----------|--------|--------------------------|\n",
    "| 0    | 0 → 1                | 1.0      | 0.5    | **0.5**                  |\n",
    "| 1    | 0 → 1                | 1.0      | 1.5    | **1.5**                  |\n",
    "| 2    | 2 → 1                | 2.0      | 1.0    | **2.0**                  |\n",
    "| 3    | 3 → 2                | 3.0      | 1.5    | **4.5**                  |\n",
    "| 4    | 3 → 2                | 3.0      | 2.0    | **6.0**                  |\n",
    "\n",
    "Aggregation Results:\n",
    "\n",
    "| Node | Incoming Messages  | Mean Aggregation (h_neigh) |\n",
    "|------|------------------|--------------------------|\n",
    "| 0    | None            | **0.0000**                |\n",
    "| 1    | {0.5, 1.5, 2.0} | **1.3333**                |\n",
    "| 2    | {4.5, 6.0}      | **5.2500**                |\n",
    "| 3    | None            | **0.0000**                |\n",
    "\n",
    "\n",
    "If we use `fn.sum('m', 'h_neigh')`:\n",
    "| Node | Sum Aggregation (h_neigh) |\n",
    "|------|--------------------------|\n",
    "| 0    | **0.0000**                |\n",
    "| 1    | **4.0000**                |\n",
    "| 2    | **10.5000**               |\n",
    "| 3    | **0.0000**                |\n",
    "\n",
    "If we use `fn.max('m', 'h_neigh')`:\n",
    "| Node | Max Aggregation (h_neigh) |\n",
    "|------|--------------------------|\n",
    "| 0    | **0.0000**                |\n",
    "| 1    | **2.0000**                |\n",
    "| 2    | **6.0000**                |\n",
    "| 3    | **0.0000**                |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Custom reduce function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a graph (with multi-edges)\n",
    "g = dgl.graph(([0, 0, 2, 3, 3], [1, 1, 1, 2, 2]))  # Multi-edges exist (0→1 and 3→2)\n",
    "\n",
    "# Step 2: Assign node features\n",
    "g.ndata['h'] = torch.tensor([1.0, 0.0, 2.0, 3.0])  # Node feature\n",
    "g.ndata['nid'] = torch.tensor([0, 1, 2, 3])  # Node IDs\n",
    "\n",
    "# Step 3: Assign edge features\n",
    "g.edata['weight'] = torch.tensor([0.5, 1.5, 1.0, 1.5, 2.0])  # Edge weights\n",
    "g.edata['id'] = torch.tensor([0, 1, 2, 3, 4])  # Edge IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> msg: tensor([1., 1., 2., 3., 3.])\n",
      "==>> nodes: tensor([[3., 3.]])\n",
      "==>> mul shape: torch.Size([1, 1])\n",
      "==>> nodes: tensor([[1., 1., 2.]])\n",
      "==>> mul shape: torch.Size([1, 1])\n",
      "Messages on edges (m):\n",
      "tensor([1., 1., 2., 3., 3.])\n",
      "\n",
      "Updated node features after aggregation (m_prod):\n",
      "tensor([[0.],\n",
      "        [2.],\n",
      "        [9.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define a message function\n",
    "def message_func(edges):\n",
    "    msg = edges.src['h']  # Compute message\n",
    "    g.edata['m'] = msg  # Manually store the message\n",
    "    print(f\"==>> msg: {msg}\")\n",
    "    return {'m': msg}  # Also return for update_all\n",
    "\n",
    "# Step 4: Define a reduce function that computes the product of all messages\n",
    "def reduce_func(nodes):\n",
    "    print(f\"==>> nodes: {nodes.mailbox['m']}\")\n",
    "    \n",
    "    # Ensure the tensor shape is correct for concatenation/storage\n",
    "    mul = torch.prod(nodes.mailbox['m'], dim=1, keepdim=True)  # Ensure (num_nodes, 1)\n",
    "    \n",
    "    print(f\"==>> mul shape: {mul.shape}\")  # Debugging\n",
    "    return {'m_prod': mul}  # Return correct shape\n",
    "\n",
    "# Step 5: Apply `update_all`\n",
    "g.update_all(message_func, reduce_func)\n",
    "\n",
    "# Print results\n",
    "print(\"Messages on edges (m):\")\n",
    "print(g.edata['m'])  # Edge messages before aggregation\n",
    "\n",
    "print(\"\\nUpdated node features after aggregation (m_prod):\")\n",
    "print(g.ndata['m_prod'])  # Aggregated values at nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Simple graph with 2D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a simple directed graph (with multi-edges)\n",
    "g = dgl.graph(([0, 0, 2, 3, 3], [1, 1, 1, 2, 2]))  # Multi-edges exist (0→1 and 3→2)\n",
    "\n",
    "# Step 2: Assign 2D node features\n",
    "g.ndata['h'] = torch.tensor([\n",
    "    [1.0, 0.5],  # Node 0\n",
    "    [0.0, 0.5],  # Node 1\n",
    "    [2.0, 0.5],  # Node 2\n",
    "    [3.0, 0.5]   # Node 3\n",
    "])  # Shape: (num_nodes, 2)\n",
    "\n",
    "g.ndata['nid'] = torch.tensor([0, 1, 2, 3])  # Node IDs\n",
    "\n",
    "# Step 3: Assign 2D edge features\n",
    "g.edata['weight'] = torch.tensor([\n",
    "    [0.5, 0.5],  # Edge 0→1\n",
    "    [1.5, 0.5],  # Edge 0→1 (multi-edge)\n",
    "    [2.0, 0.0],  # Edge 2→1\n",
    "    [1.5, 2.0],  # Edge 3→2\n",
    "    [2.0, 1.0]   # Edge 3→2 (multi-edge)\n",
    "])  # Shape: (num_edges, 2)\n",
    "\n",
    "g.edata['id'] = torch.tensor([0, 1, 2, 3, 4])  # Edge IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages on edges (msg_temp):\n",
      "tensor([[1.0000, 0.5000, 0.5000, 0.5000],\n",
      "        [1.0000, 0.5000, 1.5000, 0.5000],\n",
      "        [2.0000, 0.5000, 2.0000, 0.0000],\n",
      "        [3.0000, 0.5000, 1.5000, 2.0000],\n",
      "        [3.0000, 0.5000, 2.0000, 1.0000]])\n",
      "Messages on edges (msg_final):\n",
      "tensor([[2.5000],\n",
      "        [3.5000],\n",
      "        [4.5000],\n",
      "        [7.0000],\n",
      "        [6.5000]])\n",
      "\n",
      "Updated node features after aggregation (h_neigh):\n",
      "tensor([[0.0000],\n",
      "        [3.5000],\n",
      "        [6.7500],\n",
      "        [0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Define a message function with sum reduction\n",
    "def message_func(edges):\n",
    "    # Step 1: Concatenate source node features and edge features\n",
    "    msg_temp = torch.cat([edges.src['h'], edges.data['weight']], dim=1)  # Shape: (num_edges, 4)\n",
    "    g.edata['msg_temp'] = msg_temp\n",
    "    # Step 2: Sum across the feature dimension to reduce to (num_edges, 1)\n",
    "    msg_final = msg_temp.sum(dim=1, keepdim=True)  # Shape: (num_edges, 1)\n",
    "    g.edata['msg_final'] = msg_final\n",
    "    \n",
    "    return {'m': msg_final}  # Store the computed messages\n",
    "\n",
    "# Step 5: Apply `update_all` with mean aggregation\n",
    "g.update_all(message_func, fn.mean('m', 'h_neigh'))\n",
    "\n",
    "# Print results\n",
    "print(\"Messages on edges (msg_temp):\")\n",
    "print(g.edata['msg_temp'])\n",
    "\n",
    "# Print results\n",
    "print(\"Messages on edges (msg_final):\")\n",
    "print(g.edata['msg_final'])\n",
    "\n",
    "print(\"\\nUpdated node features after aggregation (h_neigh):\")\n",
    "print(g.ndata['h_neigh'])  # Aggregated values at nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Message Computation:\n",
    "\n",
    "Each edge computes a **single value** message by:\n",
    "\n",
    "1. **Concatenating features** `[h1, h2, w1, w2]`\n",
    "2. **Summing all values** across `dim=1` to output **one scalar per edge**.\n",
    "\n",
    "|Edge|Concatenated Values|Summed (`m`)|\n",
    "|---|---|---|\n",
    "|0 → 1|`[1.0, 0.5, 0.5, 0.5]`|**2.0**|\n",
    "|0 → 1|`[1.0, 0.5, 1.5, 0.5]`|**3.5**|\n",
    "|2 → 1|`[2.0, 0.5, 2.0, 0.0]`|**4.5**|\n",
    "|3 → 2|`[3.0, 0.5, 1.5, 2.0]`|**7.0**|\n",
    "|3 → 2|`[3.0, 0.5, 2.0, 1.0]`|**6.5**|\n",
    "\n",
    "\n",
    "Aggregation (Mean):\n",
    "\n",
    "| Node | Incoming Messages | Mean Aggregation (`h_neigh`)       |\n",
    "| ---- | ----------------- | ---------------------------------- |\n",
    "| 0    | None              | **0.0000** (no change)             |\n",
    "| 1    | {2.0, 3.5, 4.5}   | **(2.0 + 3.5 + 4.5) / 3 = 3.3333** |\n",
    "| 2    | {7.0, 6.5}        | **(7.0 + 6.5) / 2 = 6.7500**       |\n",
    "| 3    | None              | **0.0000** (no change)             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `local_scope()` Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function local_scope() in DGL creates a temporary graph scope, meaning any changes made to node features (ndata) or edge features (edata) within the block do not persist outside of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before local_scope - Original node features:\n",
      "tensor([1., 2., 3., 4.])\n",
      "\n",
      "Inside local_scope - Modified node features:\n",
      "tensor([2., 4., 6., 8.])\n",
      "\n",
      "After local_scope - Node features remain unchanged:\n",
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a simple graph\n",
    "g = dgl.graph(([0, 1, 2], [1, 2, 3]))  # A small directed graph\n",
    "\n",
    "# Step 2: Assign node features\n",
    "g.ndata['h'] = torch.tensor([1.0, 2.0, 3.0, 4.0])  # Node features\n",
    "\n",
    "print(\"Before local_scope - Original node features:\")\n",
    "print(g.ndata['h'])  # Print original node features\n",
    "\n",
    "# Step 3: Use local_scope() to temporarily modify the graph\n",
    "with g.local_scope():\n",
    "    # Apply a transformation inside the local scope\n",
    "    g.ndata['h'] = g.ndata['h'] * 2  # Multiply node features by 2\n",
    "    print(\"\\nInside local_scope - Modified node features:\")\n",
    "    print(g.ndata['h'])  # ✅ Temporary change only inside this block\n",
    "\n",
    "# Step 4: Print the node features again (should remain unchanged)\n",
    "print(\"\\nAfter local_scope - Node features remain unchanged:\")\n",
    "print(g.ndata['h'])  # ✅ Original values restored"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4775518,
     "sourceId": 8089266,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4775527,
     "sourceId": 8089281,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
