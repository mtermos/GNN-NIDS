{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-24T12:01:21.407444Z",
     "iopub.status.busy": "2024-08-24T12:01:21.407010Z",
     "iopub.status.idle": "2024-08-24T12:01:29.827271Z",
     "shell.execute_reply": "2024-08-24T12:01:29.826059Z",
     "shell.execute_reply.started": "2024-08-24T12:01:21.407404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import edge_subgraph, from_networkx\n",
    "from dgl.nn.pytorch import EdgeWeightNorm\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import src.models as models\n",
    "from src.calculate_FPR_FNR import calculate_FPR_FNR_with_global\n",
    "from src.dataset.dataset_info import datasets\n",
    "from src.numpy_encoder import NumpyEncoder\n",
    "\n",
    "# from src.models import EGAT, EGCN, EGRAPHSAGE, Model\n",
    "from src.plot_confusion_matrix import plot_confusion_matrix\n",
    "\n",
    "seed = 42  # or any constant value\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "%aimport src.models\n",
    "\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "learning_rate = 0.005\n",
    "LAMBD_2 = 0.001\n",
    "\n",
    "training_model = 'training_model'\n",
    "best_model_f1 = 'best_model_f1'\n",
    "best_model_acc = 'best_model_acc'\n",
    "best_model_loss = 'best_model_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"cic_ton_iot_5_percent\"\n",
    "# name = \"cic_ton_iot\"\n",
    "name = \"cic_ids_2017_5_percent\"\n",
    "# name = \"cic_ids_2017\"\n",
    "# name = \"cic_bot_iot\"\n",
    "# name = \"cic_ton_iot_modified\"\n",
    "# name = \"nf_ton_iotv2_modified\"\n",
    "# name = \"ccd_inid_modified\"\n",
    "# name = \"nf_uq_nids_modified\"\n",
    "# name = \"edge_iiot\"\n",
    "# name = \"nf_cse_cic_ids2018\"\n",
    "# name = \"nf_bot_iotv2\"\n",
    "# name = \"nf_uq_nids\"\n",
    "# name = \"x_iiot\"\n",
    "\n",
    "use_node_features = False\n",
    "node_features_version = 1\n",
    "\n",
    "using_masking = False\n",
    "masked_class = 2\n",
    "\n",
    "multi_class = True\n",
    "\n",
    "# dataset properties\n",
    "use_port_in_address = False\n",
    "generated_ips = False\n",
    "\n",
    "graph_type = \"flow\"\n",
    "\n",
    "sort_timestamp = False\n",
    "\n",
    "dataset = datasets[name]\n",
    "\n",
    "dataset_folder = os.path.join(\"datasets\", name)\n",
    "dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_type = \"flow\"\n",
    "    \n",
    "if multi_class:\n",
    "    g_type += \"__multi_class\"\n",
    "    \n",
    "if use_node_features:\n",
    "    g_type += \"__n_feats\"\n",
    "    \n",
    "# if k_fold:\n",
    "#     g_type += f\"__{k_fold}_fold\"\n",
    "    \n",
    "if use_port_in_address:\n",
    "    g_type += \"__ports\"\n",
    "    \n",
    "if generated_ips:\n",
    "    g_type += \"__generated_ips\"\n",
    "    \n",
    "if sort_timestamp:\n",
    "    g_type += \"__sorted\"\n",
    "else:\n",
    "    g_type += \"__unsorted\"\n",
    "    \n",
    "graphs_folder = os.path.join(dataset_folder, g_type)\n",
    "graphs_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_neighbors = [25, 10]\n",
    "# number_neighbors = None\n",
    "num_layers=2\n",
    "ndim_out = [128, 128]\n",
    "aggregation=\"mean\"\n",
    "# aggregation=\"pool\"\n",
    "activation=F.relu\n",
    "dropout=0.2\n",
    "\n",
    "my_models = [\n",
    "    # models.Model(\"e_gcn\", models.EGCN, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=False, norm=False),\n",
    "    # models.Model(\"e_gcn_res\", models.EGCN, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=True, norm=False),\n",
    "    # models.Model(\"e_graph_sage\", models.EGRAPHSAGE, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=False, aggregation=aggregation, num_neighbors=number_neighbors),\n",
    "    # models.Model(\"e_graph_sage_res\", models.EGRAPHSAGE, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=True, aggregation=aggregation, num_neighbors=number_neighbors),\n",
    "    # models.Model(\"e_gat\", models.EGAT, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=False),\n",
    "    models.Model(\"e_gat_res\", models.EGAT, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final = {}\n",
    "\n",
    "results_final[\"name\"] = name\n",
    "results_final[\"g_type\"] = g_type\n",
    "results_final[\"configuration\"] = {\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"multi_class\": multi_class,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"num_neighbors\": number_neighbors,\n",
    "    \"use_node_features\": use_node_features,\n",
    "    \"node_features_version\": node_features_version,\n",
    "    \"using_masking\": using_masking,\n",
    "    \"masked_class_num\": masked_class,\n",
    "    \"e_graph_sage_aggregation\": aggregation,\n",
    "    \"LAMBD_2\": LAMBD_2,\n",
    "}\n",
    "\n",
    "results_final[\"accuracy\"] = {}\n",
    "results_final[\"f1_score\"] = {}\n",
    "results_final[\"FPR\"] = {}\n",
    "results_final[\"FNR\"] = {}\n",
    "results_final[\"time_elapsed\"] = {}\n",
    "results_final[\"train_accuracy\"] = {}\n",
    "results_final[\"train_loss\"] = {}\n",
    "results_final[\"val_accuracy\"] = {}\n",
    "results_final[\"val_loss\"] = {}\n",
    "results_final[\"val_precision\"] = {}\n",
    "results_final[\"val_recall\"] = {}\n",
    "results_final[\"val_f1\"] = {}\n",
    "results_final[\"val_FPR\"] = {}\n",
    "results_final[\"val_FNR\"] = {}\n",
    "\n",
    "for m in my_models:\n",
    "    results_final[m.model_name] = {}\n",
    "    results_final[\"accuracy\"][m.model_name] = {}\n",
    "    results_final[\"f1_score\"][m.model_name] = {}\n",
    "    results_final[\"FPR\"][m.model_name] = {}\n",
    "    results_final[\"FNR\"][m.model_name] = {}\n",
    "    results_final[\"time_elapsed\"][m.model_name] = {}\n",
    "    \n",
    "    \n",
    "    results_final[\"train_accuracy\"][m.model_name] = []\n",
    "    results_final[\"train_loss\"][m.model_name] = []\n",
    "    results_final[\"val_accuracy\"][m.model_name] = []\n",
    "    results_final[\"val_loss\"][m.model_name] = []\n",
    "    results_final[\"val_precision\"][m.model_name] = []\n",
    "    results_final[\"val_recall\"][m.model_name] = []\n",
    "    results_final[\"val_f1\"][m.model_name] = []\n",
    "    results_final[\"val_FPR\"][m.model_name] = []\n",
    "    results_final[\"val_FNR\"][m.model_name] = []\n",
    "\n",
    "results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtime = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "dtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder_path = \"results\"\n",
    "results_folder_path1 = os.path.join(results_folder_path, name)\n",
    "results_folder_path2 = os.path.join(results_folder_path1, g_type)\n",
    "folder_path = os.path.join(results_folder_path2, dtime)\n",
    "confusion_matrices_path = os.path.join(folder_path, \"confusion_matrices\")\n",
    "os.makedirs(confusion_matrices_path, exist_ok=True)\n",
    "os.makedirs(\"temp\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Normal\", \"Attack\"]\n",
    "num_classes = 2\n",
    "if multi_class:\n",
    "    with open(os.path.join(dataset_folder, \"labels_names.pkl\"), \"rb\") as f:\n",
    "        labels_names = pickle.load(f)\n",
    "    labels_mapping = labels_names[0]\n",
    "    # labels = labels_names[1]\n",
    "    labels = list(labels_mapping.values())\n",
    "    num_classes = len(labels)\n",
    "labels, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_masking:\n",
    "    results_final[\"configuration\"][\"masked_class_name\"] = str(labels[masked_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(graphs_folder, \"training_graph.pkl\"), \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(graphs_folder, \"validation_graph.pkl\"), \"rb\") as f:\n",
    "    G_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(graphs_folder, \"testing_graph.pkl\"), \"rb\") as f:\n",
    "    G_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T12:02:22.712060Z",
     "iopub.status.busy": "2024-08-24T12:02:22.711696Z",
     "iopub.status.idle": "2024-08-24T12:03:18.648324Z",
     "shell.execute_reply": "2024-08-24T12:03:18.646671Z",
     "shell.execute_reply.started": "2024-08-24T12:02:22.712027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "edge_attributes = edge_attrs = ['h', dataset.label_col, dataset.class_num_col]\n",
    "\n",
    "if use_node_features:\n",
    "    G = from_networkx(G, edge_attrs=edge_attributes, node_attrs=[\"n_feats\"]).to(device)\n",
    "    G_val = from_networkx(G_val, edge_attrs=edge_attributes, node_attrs=[\"n_feats\"]).to(device)\n",
    "    G_test = from_networkx(G_test, edge_attrs=edge_attributes, node_attrs=[\"n_feats\"]).to(device)\n",
    "else:\n",
    "    G = from_networkx(G,  edge_attrs=edge_attributes).to(device)\n",
    "    G_val = from_networkx(G_val,  edge_attrs=edge_attributes).to(device)\n",
    "    G_test = from_networkx(G_test,  edge_attrs=edge_attributes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T12:03:18.650765Z",
     "iopub.status.busy": "2024-08-24T12:03:18.650221Z",
     "iopub.status.idle": "2024-08-24T12:03:18.657333Z",
     "shell.execute_reply": "2024-08-24T12:03:18.656030Z",
     "shell.execute_reply.started": "2024-08-24T12:03:18.650716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_features = G.edata['h'].shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_masking:\n",
    "    training_mask = G.edata[dataset.class_num_col] != masked_class\n",
    "    G = edge_subgraph(G, training_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if use_node_features:\n",
    "#     from sklearn.preprocessing import StandardScaler\n",
    "#     scaler = StandardScaler()\n",
    "#     device = th.device(\"cpu\")\n",
    "#     scaled_feats = scaler.fit_transform(G.ndata[\"n_feats\"])\n",
    "#     G.ndata[\"n_feats\"] = th.tensor(scaled_feats, device=device, dtype=th.float32)\n",
    "\n",
    "#     # Similarly, transform the validation and test features and convert them\n",
    "#     scaled_feats_val = scaler.transform(G_val.ndata[\"n_feats\"])\n",
    "#     G_val.ndata[\"n_feats\"] = th.tensor(scaled_feats_val, device=device, dtype=th.float32)\n",
    "\n",
    "#     scaled_feats_test = scaler.transform(G_test.ndata[\"n_feats\"])\n",
    "#     G_test.ndata[\"n_feats\"] = th.tensor(scaled_feats_test, device=device, dtype=th.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T12:03:18.659124Z",
     "iopub.status.busy": "2024-08-24T12:03:18.658752Z",
     "iopub.status.idle": "2024-08-24T12:03:18.690895Z",
     "shell.execute_reply": "2024-08-24T12:03:18.689736Z",
     "shell.execute_reply.started": "2024-08-24T12:03:18.659072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if use_node_features:\n",
    "    # G.ndata[\"h\"] = th.cat([G.ndata[\"n_feats\"], th.ones(G.num_nodes(), num_features)], dim=1)\n",
    "    G.ndata[\"h\"] = G.ndata[\"n_feats\"].to(device)\n",
    "else:\n",
    "    G.ndata['h'] = th.ones(G.num_nodes(), num_features, device=device)  # noqa: F821\n",
    "    \n",
    "ndim_in = G.ndata[\"h\"].shape[-1]\n",
    "\n",
    "G.ndata['h'] = th.reshape(G.ndata['h'], (G.ndata['h'].shape[0], 1, G.ndata['h'].shape[1]))\n",
    "# G.ndata['h'] = th.reshape(G.ndata['h'], (G.ndata['h'].shape[0], 1, ndim_in))\n",
    "G.edata['h'] = th.reshape(G.edata['h'], (G.edata['h'].shape[0], 1, num_features))\n",
    "\n",
    "G.edata['train_mask'] = th.ones(len(G.edata['h']), dtype=th.bool, device=device)\n",
    "# G.edata['train_mask'] = training_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T12:03:18.759982Z",
     "iopub.status.busy": "2024-08-24T12:03:18.759441Z",
     "iopub.status.idle": "2024-08-24T12:03:19.027970Z",
     "shell.execute_reply": "2024-08-24T12:03:19.026893Z",
     "shell.execute_reply.started": "2024-08-24T12:03:18.759945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if multi_class:\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                classes=np.unique(\n",
    "                                                    G.edata[dataset.class_num_col].cpu().numpy()),\n",
    "                                                y=G.edata[dataset.class_num_col].cpu().numpy())\n",
    "else:\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                    classes=np.unique(\n",
    "                                                        G.edata[dataset.label_col].cpu().numpy()),\n",
    "                                                    y=G.edata[dataset.label_col].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_masking:\n",
    "    class_weights=np.insert(class_weights, masked_class, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T12:03:19.029947Z",
     "iopub.status.busy": "2024-08-24T12:03:19.029509Z",
     "iopub.status.idle": "2024-08-24T12:03:19.046918Z",
     "shell.execute_reply": "2024-08-24T12:03:19.045391Z",
     "shell.execute_reply.started": "2024-08-24T12:03:19.029904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_weights = th.FloatTensor(class_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T12:03:19.053163Z",
     "iopub.status.busy": "2024-08-24T12:03:19.052745Z",
     "iopub.status.idle": "2024-08-24T12:03:19.060739Z",
     "shell.execute_reply": "2024-08-24T12:03:19.059331Z",
     "shell.execute_reply.started": "2024-08-24T12:03:19.053117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.cpu().argmax(1) == labels.cpu()).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_class:\n",
    "    val_labels = G_val.edata[dataset.class_num_col]\n",
    "else:\n",
    "    val_labels = G_val.edata[dataset.label_col]\n",
    "\n",
    "if use_node_features:\n",
    "    # G_val.ndata[\"feature\"] = th.cat([G_val.ndata[\"n_feats\"], th.ones(G_val.num_nodes(), num_features)], dim=1)\n",
    "    G_val.ndata[\"feature\"] = G_val.ndata[\"n_feats\"]\n",
    "else:\n",
    "    G_val.ndata['feature'] = th.ones(G_val.num_nodes(),  num_features, device=device)\n",
    "\n",
    "G_val.edata['val_mask'] = th.ones(len(G_val.edata['h']), dtype=th.bool, device=device)\n",
    "# G_val.edata['val_mask'] = val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_val.ndata['feature'] = th.reshape(G_val.ndata['feature'], (G_val.ndata['feature'].shape[0], 1, G_val.ndata['feature'].shape[1]))\n",
    "G_val.edata['h'] = th.reshape(G_val.edata['h'], (G_val.edata['h'].shape[0], 1, G_val.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if multi_class:\n",
    "    test_labels = G_test.edata[dataset.class_num_col]\n",
    "else:\n",
    "    test_labels = G_test.edata[dataset.label_col]\n",
    "\n",
    "if use_node_features:\n",
    "    # G_test.ndata[\"feature\"] = th.cat([G_test.ndata[\"n_feats\"], th.ones(G_test.num_nodes(), num_features)], dim=1)\n",
    "    G_test.ndata[\"feature\"] = G_test.ndata[\"n_feats\"]\n",
    "else:\n",
    "    G_test.ndata['feature'] = th.ones(G_test.num_nodes(),  num_features, device=device)\n",
    "\n",
    "G_test.edata['test_mask'] = th.ones(len(G_test.edata['h']), dtype=th.bool, device=device)\n",
    "# G_test.edata['test_mask'] = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "G_test.ndata['feature'] = th.reshape(G_test.ndata['feature'], (G_test.ndata['feature'].shape[0], 1, G_test.ndata['feature'].shape[1]))\n",
    "G_test.edata['h'] = th.reshape(G_test.edata['h'], (G_test.edata['h'].shape[0], 1, G_test.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model:models.Model):\n",
    "    extra_param = {}\n",
    "    if model.model_class == models.EGRAPHSAGE:\n",
    "        extra_param = {'num_neighbors': model.num_neighbors, \"aggregation\": model.aggregation}\n",
    "    elif model.model_class == models.EGCN:\n",
    "        extra_param = {'norm': model.norm}\n",
    "        \n",
    "    return model.model_class(ndim_in, num_features, model.ndim_out, num_layers=model.num_layers, activation=model.activation, dropout=model.dropout,\n",
    "                             residual=model.residual, num_class=num_classes, **extra_param)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model:models.Model, graph, actual_labels, loss_fn, results_f, _labels):\n",
    "    start_time = timeit.default_timer()\n",
    "    model.models[training_model].eval()\n",
    "\n",
    "    if model.norm:\n",
    "        edge_weight = th.ones(graph.num_edges(), dtype=th.float32)\n",
    "        norm = EdgeWeightNorm(norm='both')\n",
    "        norm_edge_weight = norm(graph, edge_weight)\n",
    "        graph.edata['norm_weight'] = norm_edge_weight\n",
    "\n",
    "    node_features_test = graph.ndata['feature']\n",
    "    edge_features_test = graph.edata['h']\n",
    "    \n",
    "    with th.no_grad():\n",
    "        test_pred = model.models[training_model](graph, node_features_test, edge_features_test)\n",
    "        \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "    loss = loss_fn(test_pred.cpu(), actual_labels)\n",
    "    \n",
    "    test_pred = test_pred.argmax(1)\n",
    "    test_pred = th.Tensor.cpu(test_pred).detach().numpy()\n",
    "\n",
    "    if multi_class:\n",
    "        actual = np.vectorize(labels_names[0].get)(actual_labels)\n",
    "        test_pred = np.vectorize(labels_names[0].get)(test_pred)\n",
    "    else:\n",
    "        actual = [\"Normal\" if i == 0 else \"Attack\" for i in actual_labels]\n",
    "        test_pred = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred]\n",
    "\n",
    "    cr = classification_report(actual, test_pred, digits=4, output_dict=True, zero_division=0)\n",
    "    cm = confusion_matrix(actual, test_pred, labels=_labels)\n",
    "    results_fpr_fnr = calculate_FPR_FNR_with_global(cm)\n",
    "    \n",
    "    val_acc = cr[\"accuracy\"] * 100\n",
    "    val_f1 = cr['weighted avg']['f1-score'] * 100\n",
    "    val_loss = loss.item()\n",
    "    results_f[\"val_accuracy\"][model.model_name].append(val_acc)\n",
    "    results_f[\"val_loss\"][model.model_name].append(val_loss)\n",
    "    results_f[\"val_precision\"][model.model_name].append(cr['weighted avg']['precision'] * 100)\n",
    "    results_f[\"val_recall\"][model.model_name].append(cr['weighted avg']['recall'] * 100)\n",
    "    results_f[\"val_f1\"][model.model_name].append(val_f1)\n",
    "    results_f[\"val_FPR\"][model.model_name].append(results_fpr_fnr[\"global\"][\"FPR\"])\n",
    "    results_f[\"val_FNR\"][model.model_name].append(results_fpr_fnr[\"global\"][\"FNR\"])\n",
    "    \n",
    "    return (val_acc, val_loss, val_f1, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: models.Model, graph, _labels):\n",
    "    node_features = graph.ndata['h']\n",
    "    edge_features = graph.edata['h']\n",
    "\n",
    "    edge_label = graph.edata[dataset.class_num_col if multi_class else dataset.label_col]\n",
    "        \n",
    "    train_mask = graph.edata['train_mask']\n",
    "\n",
    "    if model.norm:\n",
    "        edge_weight = th.ones(graph.num_edges(), dtype=th.float32)\n",
    "        norm = EdgeWeightNorm(norm='both')\n",
    "        norm_edge_weight = norm(graph, edge_weight)\n",
    "        graph.edata['norm_weight'] = norm_edge_weight\n",
    "\n",
    "    model.models[training_model].to(device)\n",
    "    \n",
    "    opt = th.optim.Adam(model.models[training_model].parameters(), lr = learning_rate, weight_decay=LAMBD_2)\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_acc = 0\n",
    "    best_loss = np.inf\n",
    "    best_f1_epoch = 0\n",
    "    best_acc_epoch = 0\n",
    "    best_loss_epoch = 0\n",
    "    for epoch in range(1, num_epochs):\n",
    "        model.models[training_model].train()\n",
    "        pred = model.models[training_model](graph, node_features, edge_features[train_mask])\n",
    "        loss = criterion(pred[train_mask], edge_label[train_mask])\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if epoch == 1:\n",
    "            print(\"================================\")\n",
    "            print(\"================================\")\n",
    "            print(f\"Training Model: {model.model_name}\")\n",
    "            print(f\"Edge label shape: {edge_label.shape}\")\n",
    "            print(f\"Edge label unique values: {th.unique(edge_label)}\")\n",
    "            print(f\"Pred shape: {pred.shape}\")\n",
    "            \n",
    "        train_acc = compute_accuracy(pred[train_mask], edge_label[train_mask]) * 100\n",
    "\n",
    "        train_pred = pred[train_mask].argmax(1).cpu()\n",
    "        train_pred = th.Tensor.cpu(train_pred).detach().numpy()\n",
    "\n",
    "        if multi_class:\n",
    "            actual = np.vectorize(labels_names[0].get)(edge_label[train_mask].cpu())\n",
    "            train_pred = np.vectorize(labels_names[0].get)(train_pred)\n",
    "        else:\n",
    "            actual = [\"Normal\" if i == 0 else \"Attack\" for i in edge_label[train_mask]]\n",
    "            train_pred = [\"Normal\" if i == 0 else \"Attack\" for i in train_pred]\n",
    "        cr = classification_report(actual, train_pred, digits=4, output_dict=True, zero_division=0)\n",
    "        train_f1 = cr['weighted avg']['f1-score'] * 100   \n",
    "\n",
    "        print(f\"Model: {model.model_name} -- Epoch: {epoch} -- Training acc: {train_acc:.2f}  -- Training f1: {train_f1:.2f} -- Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        results_final[\"train_accuracy\"][model.model_name].append(train_acc)\n",
    "        results_final[\"train_loss\"][model.model_name].append(loss.item())\n",
    "        \n",
    "        val_acc, val_loss, val_f1, elapsed = evaluate_model(model, G_val, val_labels.cpu(), criterion, results_final, _labels)\n",
    "\n",
    "        print(f\"Model: {model.model_name} -- Epoch: {epoch} -- Validation acc: {val_acc:.2f} -- Validation f1: {val_f1:.2f} -- Validation loss: {val_loss:.4f}\")\n",
    "        print(\"Time for validation: \", str(elapsed) + ' seconds')    \n",
    "        \n",
    "        if best_f1 < val_f1:\n",
    "            best_f1_epoch = epoch\n",
    "            best_f1 = val_f1\n",
    "            model.models[best_model_f1].load_state_dict(model.models[training_model].state_dict().copy())\n",
    "            th.save(model.models[training_model], f\"temp/best_model_{model.model_name}.pth\")\n",
    "\n",
    "        if best_acc < val_acc:\n",
    "            best_acc_epoch = epoch\n",
    "            best_acc = val_acc\n",
    "            model.models[best_model_acc].load_state_dict(model.models[training_model].state_dict().copy())\n",
    "\n",
    "        if best_loss > val_loss:\n",
    "            best_loss_epoch = epoch\n",
    "            best_loss = val_loss\n",
    "            model.models[best_model_loss].load_state_dict(model.models[training_model].state_dict().copy())\n",
    "            \n",
    "    print(f\"==>> best_f1: {best_f1} at epoch: {best_f1_epoch}\")\n",
    "    print(f\"==>> best_acc: {best_acc} at epoch: {best_acc_epoch}\")\n",
    "    print(f\"==>> best_loss: {best_loss} at epoch: {best_loss_epoch}\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, best_model_type, model_name, norm, graph, actual_labels, results_f, _labels):\n",
    "    print(\"=======================\")\n",
    "    print(f\"testing model: {model_name}\")\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    model.eval()\n",
    "    \n",
    "    if norm:\n",
    "        edge_weight = th.ones(graph.num_edges(), dtype=th.float32)\n",
    "        norm = EdgeWeightNorm(norm='both')\n",
    "        norm_edge_weight = norm(graph, edge_weight)\n",
    "        graph.edata['norm_weight'] = norm_edge_weight\n",
    "    \n",
    "    node_features_test = graph.ndata['feature']\n",
    "    edge_features_test = graph.edata['h']\n",
    "    \n",
    "    with th.no_grad():\n",
    "        test_pred = model(graph, node_features_test, edge_features_test)\n",
    "        \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    test_pred = test_pred.argmax(1)\n",
    "    test_pred = th.Tensor.cpu(test_pred).detach().numpy()\n",
    "    \n",
    "    if multi_class:\n",
    "        actual = np.vectorize(labels_names[0].get)(actual_labels)\n",
    "        test_pred = np.vectorize(labels_names[0].get)(test_pred)\n",
    "    else:\n",
    "        actual = [\"Normal\" if i == 0 else \"Attack\" for i in actual_labels]\n",
    "        test_pred = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred]\n",
    "\n",
    "    cr = classification_report(actual, test_pred, digits=4, output_dict=True, zero_division=0)\n",
    "    cm = confusion_matrix(actual, test_pred, labels=_labels)\n",
    "    cm_normalized = confusion_matrix(actual, test_pred, labels=labels, normalize=\"true\")\n",
    "    results_fpr_fnr = calculate_FPR_FNR_with_global(cm)\n",
    "\n",
    "    # Log metrics\n",
    "    results_f[model_name][best_model_type] = {}\n",
    "    \n",
    "    results_f[model_name][best_model_type][\"elapsed\"] = elapsed\n",
    "    results_f[model_name][best_model_type][\"classification_report\"] = cr\n",
    "    results_f[model_name][best_model_type][\"results_fpr_fnr\"] = results_fpr_fnr\n",
    "    results_f[\"accuracy\"][model_name][best_model_type] = cr[\"accuracy\"] * 100\n",
    "    results_f[\"f1_score\"][model_name][best_model_type] = cr['weighted avg']['f1-score'] * 100\n",
    "    results_f[\"FPR\"][model_name][best_model_type] = results_fpr_fnr[\"global\"][\"FPR\"]\n",
    "    results_f[\"FNR\"][model_name][best_model_type] = results_fpr_fnr[\"global\"][\"FNR\"]\n",
    "    results_f[\"time_elapsed\"][model_name][best_model_type] = elapsed\n",
    "\n",
    "    print(classification_report(actual, test_pred, digits=4, zero_division=0))\n",
    "    \n",
    "    return actual, test_pred, cm, cm_normalized\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training GNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in my_models:\n",
    "    m.models = {name: create_model(m) for name in [training_model, best_model_f1, best_model_acc, best_model_loss]}\n",
    "    train_model(m, G, labels)\n",
    "    actual, test_pred, cm, cm_normalized = test_model(m.models[best_model_f1], best_model_f1, m.model_name, m.norm, G_test, test_labels, results_final, labels)\n",
    "    actual, test_pred, cm, cm_normalized = test_model(m.models[best_model_acc], best_model_acc, m.model_name, m.norm, G_test, test_labels, results_final, labels)\n",
    "    actual, test_pred, cm, cm_normalized = test_model(m.models[best_model_loss], best_model_loss, m.model_name, m.norm, G_test, test_labels, results_final, labels)\n",
    "    with open(os.path.join(folder_path, \"results.json\"), \"w\") as f:\n",
    "        f.writelines(json.dumps(results_final, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in my_models:\n",
    "    # actual, test_pred, cm, cm_normalized = test_model(m.best_model, m.model_name, m.norm, G_test, test_labels, results_final, labels)\n",
    "    # plot_confusion_matrix(cm=cm,\n",
    "    #                       normalize=False,\n",
    "    #                       target_names=labels,\n",
    "    #                       title=f\"Confusion Matrix of {m.model_name}\",\n",
    "    #                       file_path=f\"{confusion_matrices_path}/{m.model_name}.png\")\n",
    "    \n",
    "    # plot_confusion_matrix(cm=cm_normalized,\n",
    "    #                       normalize=False,\n",
    "    #                       normalized=True,\n",
    "    #                       target_names=labels,\n",
    "    #                       title=f\"Normalized Confusion Matrix of {m.model_name}\",\n",
    "    #                       file_path=f\"{confusion_matrices_path}/{m.model_name}_normalized.png\")\n",
    "    \n",
    "    # with open(os.path.join(folder_path, \"actual.json\"), \"w\") as f:\n",
    "    #     f.writelines(json.dumps(actual, cls=NumpyEncoder))\n",
    "        \n",
    "    # with open(os.path.join(folder_path, f\"{m.model_name}_pred.json\"), \"w\") as f:\n",
    "    #     f.writelines(json.dumps(test_pred, cls=NumpyEncoder))\n",
    "        \n",
    "    # with open(os.path.join(folder_path, \"results.json\"), \"w\") as f:\n",
    "    #     f.writelines(json.dumps(results_final, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import importlib.util\n",
    "# import sys\n",
    "# def add_lib(module_name, path):\n",
    "#     spec = importlib.util.spec_from_file_location(module_name, path)\n",
    "#     dataset_info = importlib.util.module_from_spec(spec)\n",
    "#     sys.modules[module_name] = dataset_info\n",
    "#     spec.loader.exec_module(dataset_info)\n",
    "\n",
    "# add_lib(\"e_gat\", \"C:/Users/Administrateur/Desktop/GNN-NIDS/src/models/e_gat_my_code.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in my_models:\n",
    "#     m.best_model = th.load(f\"temp/best_model_{m.model_name}.pth\")\n",
    "#     print(f\"temp/best_model_{m.model_name}.pth\")\n",
    "    \n",
    "#     actual, test_pred, cm, cm_normalized = test_model(m, G_test, test_labels, results_final, labels)\n",
    "#     plot_confusion_matrix(cm=cm,\n",
    "#                           normalize=False,\n",
    "#                           target_names=labels,\n",
    "#                           title=f\"Confusion Matrix of {m.model_name}\",\n",
    "#                           file_path=f\"{confusion_matrices_path}/{m.model_name}.png\")\n",
    "    \n",
    "#     plot_confusion_matrix(cm=cm_normalized,\n",
    "#                           normalize=False,\n",
    "#                           normalized=True,\n",
    "#                           target_names=labels,\n",
    "#                           title=f\"Normalized Confusion Matrix of {m.model_name}\",\n",
    "#                           file_path=f\"{confusion_matrices_path}/{m.model_name}_normalized.png\")\n",
    "    \n",
    "#     with open(os.path.join(folder_path, \"actual.json\"), \"w\") as f:\n",
    "#         f.writelines(json.dumps(actual, cls=NumpyEncoder))\n",
    "        \n",
    "#     with open(os.path.join(folder_path, f\"{m.model_name}_pred.json\"), \"w\") as f:\n",
    "#         f.writelines(json.dumps(test_pred, cls=NumpyEncoder))\n",
    "        \n",
    "#     with open(os.path.join(folder_path, \"results.json\"), \"w\") as f:\n",
    "#         f.writelines(json.dumps(results_final, cls=NumpyEncoder))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4775518,
     "sourceId": 8089266,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4775527,
     "sourceId": 8089281,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
