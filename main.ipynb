{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-24T12:01:21.407444Z","iopub.status.busy":"2024-08-24T12:01:21.407010Z","iopub.status.idle":"2024-08-24T12:01:29.827271Z","shell.execute_reply":"2024-08-24T12:01:29.826059Z","shell.execute_reply.started":"2024-08-24T12:01:21.407404Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 1\n","\n","import json\n","import os\n","import pickle\n","import time\n","import timeit\n","import random\n","\n","import numpy as np\n","\n","os.environ[\"DGLBACKEND\"] = \"pytorch\"\n","\n","import torch as th\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dgl import from_networkx, edge_subgraph\n","from dgl.nn.pytorch import EdgeWeightNorm\n","from sklearn.metrics import (\n","    classification_report,\n","    confusion_matrix,\n",")\n","from sklearn.utils import class_weight\n","\n","from src.calculate_FPR_FNR import calculate_FPR_FNR_with_global\n","from src.dataset.dataset_info import datasets\n","import src.models as models\n","# from src.models import EGAT, EGCN, EGRAPHSAGE, Model\n","from src.plot_confusion_matrix import plot_confusion_matrix\n","from src.numpy_encoder import NumpyEncoder\n","\n","seed = 42  # or any constant value\n","random.seed(seed)\n","np.random.seed(seed)\n","th.manual_seed(seed)\n","\n","%aimport src.models\n","\n","num_epochs = 50\n","batch_size = 128\n","learning_rate = 0.005\n","LAMBD_2 = 0.001"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["'datasets\\\\cic_ton_iot'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# name = \"cic_ton_iot_5_percent\"\n","name = \"cic_ton_iot\"\n","# name = \"cic_ids_2017_5_percent\"\n","# name = \"cic_ids_2017\"\n","# name = \"cic_bot_iot\"\n","# name = \"cic_ton_iot_modified\"\n","# name = \"nf_ton_iotv2_modified\"\n","# name = \"ccd_inid_modified\"\n","# name = \"nf_uq_nids_modified\"\n","# name = \"edge_iiot\"\n","# name = \"nf_cse_cic_ids2018\"\n","# name = \"nf_bot_iotv2\"\n","# name = \"nf_uq_nids\"\n","# name = \"x_iiot\"\n","\n","use_node_features = False\n","node_features_version = 1\n","\n","using_masking = False\n","masked_class = 2\n","\n","multi_class = True\n","\n","# dataset properties\n","use_port_in_address = False\n","generated_ips = False\n","\n","graph_type = \"flow\"\n","\n","sort_timestamp = False\n","\n","dataset = datasets[name]\n","\n","dataset_folder = os.path.join(\"datasets\", name)\n","dataset_folder"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["'datasets\\\\cic_ton_iot\\\\flow__multi_class__unsorted'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["g_type = \"flow\"\n","    \n","if multi_class:\n","    g_type += \"__multi_class\"\n","    \n","if use_node_features:\n","    g_type += \"__n_feats\"\n","    \n","# if k_fold:\n","#     g_type += f\"__{k_fold}_fold\"\n","    \n","if use_port_in_address:\n","    g_type += \"__ports\"\n","    \n","if generated_ips:\n","    g_type += \"__generated_ips\"\n","    \n","if sort_timestamp:\n","    g_type += \"__sorted\"\n","else:\n","    g_type += \"__unsorted\"\n","    \n","graphs_folder = os.path.join(dataset_folder, g_type)\n","graphs_folder"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["number_neighbors = [25, 10]\n","# number_neighbors = None\n","num_layers=2\n","ndim_out = [128, 128]\n","aggregation=\"mean\"\n","# aggregation=\"pool\"\n","# aggregation=\"lstm\"\n","# aggregation=\"gcn\"\n","activation=F.relu\n","dropout=0.2\n","\n","my_models = [\n","    # models.Model(\"e_gcn\", models.EGCN, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=False, norm=False),\n","    # models.Model(\"e_gcn_res\", models.EGCN, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=True, norm=False),\n","    # models.Model(\"e_graph_sage\", models.EGRAPHSAGE, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=False, aggregation=aggregation, num_neighbors=number_neighbors),\n","    # models.Model(\"e_graph_sage_res\", models.EGRAPHSAGE, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=True, aggregation=aggregation, num_neighbors=number_neighbors),\n","    # models.Model(\"e_gat\", models.EGAT, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=False),\n","    models.Model(\"e_gat_res\", models.EGAT, num_layers=num_layers, ndim_out= ndim_out, activation=activation, dropout=dropout, residual=True),\n","]"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["{'name': 'cic_ton_iot',\n"," 'g_type': 'flow__multi_class__unsorted',\n"," 'configuration': {'num_epochs': 50,\n","  'multi_class': True,\n","  'batch_size': 128,\n","  'learning_rate': 0.005,\n","  'num_neighbors': [25, 10],\n","  'use_node_features': False,\n","  'node_features_version': 1,\n","  'using_masking': False,\n","  'masked_class_num': 2,\n","  'e_graph_sage_aggregation': 'mean',\n","  'LAMBD_2': 0.001},\n"," 'accuracy': {'e_gat_res': []},\n"," 'f1_score': {},\n"," 'FPR': {},\n"," 'FNR': {},\n"," 'time_elapsed': {'e_gat_res': []},\n"," 'train_accuracy': {'e_gat_res': []},\n"," 'train_loss': {'e_gat_res': []},\n"," 'val_accuracy': {'e_gat_res': []},\n"," 'val_loss': {'e_gat_res': []},\n"," 'val_precision': {'e_gat_res': []},\n"," 'val_recall': {'e_gat_res': []},\n"," 'val_f1': {'e_gat_res': []},\n"," 'val_FPR': {'e_gat_res': []},\n"," 'val_FNR': {'e_gat_res': []},\n"," 'e_gat_res': {}}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["results_final = {}\n","\n","results_final[\"name\"] = name\n","results_final[\"g_type\"] = g_type\n","results_final[\"configuration\"] = {\n","    \"num_epochs\": num_epochs,\n","    \"multi_class\": multi_class,\n","    \"batch_size\": batch_size,\n","    \"learning_rate\": learning_rate,\n","    \"num_neighbors\": number_neighbors,\n","    \"use_node_features\": use_node_features,\n","    \"node_features_version\": node_features_version,\n","    \"using_masking\": using_masking,\n","    \"masked_class_num\": masked_class,\n","    \"e_graph_sage_aggregation\": aggregation,\n","    \"LAMBD_2\": LAMBD_2,\n","}\n","\n","results_final[\"accuracy\"] = {}\n","results_final[\"f1_score\"] = {}\n","results_final[\"FPR\"] = {}\n","results_final[\"FNR\"] = {}\n","results_final[\"time_elapsed\"] = {}\n","results_final[\"train_accuracy\"] = {}\n","results_final[\"train_loss\"] = {}\n","results_final[\"val_accuracy\"] = {}\n","results_final[\"val_loss\"] = {}\n","results_final[\"val_precision\"] = {}\n","results_final[\"val_recall\"] = {}\n","results_final[\"val_f1\"] = {}\n","results_final[\"val_FPR\"] = {}\n","results_final[\"val_FNR\"] = {}\n","\n","for m in my_models:\n","    results_final[m.model_name] = {}\n","    results_final[\"accuracy\"][m.model_name] = []\n","    results_final[\"time_elapsed\"][m.model_name] = []\n","    results_final[\"train_accuracy\"][m.model_name] = []\n","    results_final[\"train_loss\"][m.model_name] = []\n","    results_final[\"val_accuracy\"][m.model_name] = []\n","    results_final[\"val_loss\"][m.model_name] = []\n","    results_final[\"val_precision\"][m.model_name] = []\n","    results_final[\"val_recall\"][m.model_name] = []\n","    results_final[\"val_f1\"][m.model_name] = []\n","    results_final[\"val_FPR\"][m.model_name] = []\n","    results_final[\"val_FNR\"][m.model_name] = []\n","\n","results_final"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["'20250127-084740'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dtime = time.strftime(\"%Y%m%d-%H%M%S\")\n","dtime"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["results_folder_path = \"results\"\n","results_folder_path1 = os.path.join(results_folder_path, name)\n","results_folder_path2 = os.path.join(results_folder_path1, g_type)\n","folder_path = os.path.join(results_folder_path2, dtime)\n","confusion_matrices_path = os.path.join(folder_path, \"confusion_matrices\")\n","os.makedirs(confusion_matrices_path, exist_ok=True)\n","os.makedirs(\"temp\", exist_ok=True)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["([np.str_('Benign'),\n","  np.str_('backdoor'),\n","  np.str_('ddos'),\n","  np.str_('dos'),\n","  np.str_('injection'),\n","  np.str_('mitm'),\n","  np.str_('password'),\n","  np.str_('ransomware'),\n","  np.str_('scanning'),\n","  np.str_('xss')],\n"," 10)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["labels = [\"Normal\", \"Attack\"]\n","num_classes = 2\n","if multi_class:\n","    with open(os.path.join(dataset_folder, \"labels_names.pkl\"), \"rb\") as f:\n","        labels_names = pickle.load(f)\n","    labels_mapping = labels_names[0]\n","    # labels = labels_names[1]\n","    labels = list(labels_mapping.values())\n","    num_classes = len(labels)\n","labels, num_classes"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["if using_masking:\n","    results_final[\"configuration\"][\"masked_class_name\"] = str(labels[masked_class])"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["with open(os.path.join(graphs_folder, \"training_graph.pkl\"), \"rb\") as f:\n","    G = pickle.load(f)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["with open(os.path.join(graphs_folder, \"validation_graph.pkl\"), \"rb\") as f:\n","    G_val = pickle.load(f)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["with open(os.path.join(graphs_folder, \"testing_graph.pkl\"), \"rb\") as f:\n","    G_test = pickle.load(f)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:02:22.712060Z","iopub.status.busy":"2024-08-24T12:02:22.711696Z","iopub.status.idle":"2024-08-24T12:03:18.648324Z","shell.execute_reply":"2024-08-24T12:03:18.646671Z","shell.execute_reply.started":"2024-08-24T12:02:22.712027Z"},"trusted":true},"outputs":[],"source":["edge_attributes = edge_attrs = ['h', dataset.label_col, dataset.class_num_col]\n","\n","if use_node_features:\n","    G = from_networkx(G, edge_attrs=edge_attributes, node_attrs=[\"n_feats\"])\n","    G_val = from_networkx(G_val, edge_attrs=edge_attributes, node_attrs=[\"n_feats\"])  \n","    G_test = from_networkx(G_test, edge_attrs=edge_attributes, node_attrs=[\"n_feats\"])  \n","else:\n","    G = from_networkx(G,  edge_attrs=edge_attributes)\n","    G_val = from_networkx(G_val,  edge_attrs=edge_attributes)\n","    G_test = from_networkx(G_test,  edge_attrs=edge_attributes)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:03:18.650765Z","iopub.status.busy":"2024-08-24T12:03:18.650221Z","iopub.status.idle":"2024-08-24T12:03:18.657333Z","shell.execute_reply":"2024-08-24T12:03:18.656030Z","shell.execute_reply.started":"2024-08-24T12:03:18.650716Z"},"trusted":true},"outputs":[{"data":{"text/plain":["37"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["num_features = G.edata['h'].shape[1]\n","num_features"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["if using_masking:\n","    # Create masks for edges\n","    training_mask = G.edata[dataset.class_num_col] != masked_class  # Include all edges except class 3\n","    # val_mask = G_val.edata[dataset.class_num_col] == masked_class    # Include only edges of class 3 (or other validation logic)\n","    # test_mask = G_test.edata[dataset.class_num_col] == masked_class   # Include only edges of class 3\n","    \n","    G = edge_subgraph(G, training_mask)\n","    # G_val = edge_subgraph(G_val, val_mask)\n","    # G_test = edge_subgraph(G_test, test_mask)\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# if use_node_features:\n","#     from sklearn.preprocessing import StandardScaler\n","#     scaler = StandardScaler()\n","#     device = th.device(\"cpu\")\n","#     scaled_feats = scaler.fit_transform(G.ndata[\"n_feats\"])\n","#     G.ndata[\"n_feats\"] = th.tensor(scaled_feats, device=device, dtype=th.float32)\n","\n","#     # Similarly, transform the validation and test features and convert them\n","#     scaled_feats_val = scaler.transform(G_val.ndata[\"n_feats\"])\n","#     G_val.ndata[\"n_feats\"] = th.tensor(scaled_feats_val, device=device, dtype=th.float32)\n","\n","#     scaled_feats_test = scaler.transform(G_test.ndata[\"n_feats\"])\n","#     G_test.ndata[\"n_feats\"] = th.tensor(scaled_feats_test, device=device, dtype=th.float32)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:03:18.659124Z","iopub.status.busy":"2024-08-24T12:03:18.658752Z","iopub.status.idle":"2024-08-24T12:03:18.690895Z","shell.execute_reply":"2024-08-24T12:03:18.689736Z","shell.execute_reply.started":"2024-08-24T12:03:18.659072Z"},"trusted":true},"outputs":[],"source":["if use_node_features:\n","    # G.ndata[\"h\"] = th.cat([G.ndata[\"n_feats\"], th.ones(G.num_nodes(), num_features)], dim=1)\n","    G.ndata[\"h\"] = G.ndata[\"n_feats\"]\n","else:\n","    G.ndata['h'] = th.ones(G.num_nodes(), num_features)  # noqa: F821\n","    \n","ndim_in = G.ndata[\"h\"].shape[-1]\n","\n","G.ndata['h'] = th.reshape(G.ndata['h'], (G.ndata['h'].shape[0], 1, G.ndata['h'].shape[1]))\n","# G.ndata['h'] = th.reshape(G.ndata['h'], (G.ndata['h'].shape[0], 1, ndim_in))\n","G.edata['h'] = th.reshape(G.edata['h'], (G.edata['h'].shape[0], 1, num_features))\n","\n","G.edata['train_mask'] = th.ones(len(G.edata['h']), dtype=th.bool)\n","# G.edata['train_mask'] = training_mask"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:03:18.759982Z","iopub.status.busy":"2024-08-24T12:03:18.759441Z","iopub.status.idle":"2024-08-24T12:03:19.027970Z","shell.execute_reply":"2024-08-24T12:03:19.026893Z","shell.execute_reply.started":"2024-08-24T12:03:18.759945Z"},"trusted":true},"outputs":[],"source":["if multi_class:\n","    class_weights = class_weight.compute_class_weight('balanced',\n","                                                classes=np.unique(\n","                                                    G.edata[dataset.class_num_col].cpu().numpy()),\n","                                                y=G.edata[dataset.class_num_col].cpu().numpy())\n","else:\n","    class_weights = class_weight.compute_class_weight('balanced',\n","                                                    classes=np.unique(\n","                                                        G.edata[dataset.label_col].cpu().numpy()),\n","                                                    y=G.edata[dataset.label_col].cpu().numpy())"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["if using_masking:\n","    class_weights=np.insert(class_weights, masked_class, 0)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:03:19.029947Z","iopub.status.busy":"2024-08-24T12:03:19.029509Z","iopub.status.idle":"2024-08-24T12:03:19.046918Z","shell.execute_reply":"2024-08-24T12:03:19.045391Z","shell.execute_reply.started":"2024-08-24T12:03:19.029904Z"},"trusted":true},"outputs":[],"source":["class_weights = th.FloatTensor(class_weights)\n","\n","criterion = nn.CrossEntropyLoss(weight=class_weights)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:03:19.053163Z","iopub.status.busy":"2024-08-24T12:03:19.052745Z","iopub.status.idle":"2024-08-24T12:03:19.060739Z","shell.execute_reply":"2024-08-24T12:03:19.059331Z","shell.execute_reply.started":"2024-08-24T12:03:19.053117Z"},"trusted":true},"outputs":[],"source":["def compute_accuracy(pred, labels):\n","    return (pred.argmax(1) == labels).float().mean().item()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["if multi_class:\n","    val_labels = G_val.edata[dataset.class_num_col]\n","else:\n","    val_labels = G_val.edata[dataset.label_col]\n","\n","if use_node_features:\n","    # G_val.ndata[\"feature\"] = th.cat([G_val.ndata[\"n_feats\"], th.ones(G_val.num_nodes(), num_features)], dim=1)\n","    G_val.ndata[\"feature\"] = G_val.ndata[\"n_feats\"]\n","else:\n","    G_val.ndata['feature'] = th.ones(G_val.num_nodes(),  num_features)\n","\n","G_val.edata['val_mask'] = th.ones(len(G_val.edata['h']), dtype=th.bool)\n","# G_val.edata['val_mask'] = val_mask"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["G_val.ndata['feature'] = th.reshape(G_val.ndata['feature'], (G_val.ndata['feature'].shape[0], 1, G_val.ndata['feature'].shape[1]))\n","G_val.edata['h'] = th.reshape(G_val.edata['h'], (G_val.edata['h'].shape[0], 1, G_val.edata['h'].shape[1]))"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["if multi_class:\n","    test_labels = G_test.edata[dataset.class_num_col]\n","else:\n","    test_labels = G_test.edata[dataset.label_col]\n","\n","if use_node_features:\n","    # G_test.ndata[\"feature\"] = th.cat([G_test.ndata[\"n_feats\"], th.ones(G_test.num_nodes(), num_features)], dim=1)\n","    G_test.ndata[\"feature\"] = G_test.ndata[\"n_feats\"]\n","else:\n","    G_test.ndata['feature'] = th.ones(G_test.num_nodes(),  num_features)\n","\n","G_test.edata['test_mask'] = th.ones(len(G_test.edata['h']), dtype=th.bool)\n","# G_test.edata['test_mask'] = test_mask"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[],"source":["G_test.ndata['feature'] = th.reshape(G_test.ndata['feature'], (G_test.ndata['feature'].shape[0], 1, G_test.ndata['feature'].shape[1]))\n","G_test.edata['h'] = th.reshape(G_test.edata['h'], (G_test.edata['h'].shape[0], 1, G_test.edata['h'].shape[1]))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def evaluate_model(model:models.Model, graph, actual_labels, loss_fn, results_f, _labels):\n","    start_time = timeit.default_timer()\n","    model.trained_model.eval()\n","\n","    if model.norm:\n","        edge_weight = th.ones(graph.num_edges(), dtype=th.float32)\n","        norm = EdgeWeightNorm(norm='both')\n","        norm_edge_weight = norm(graph, edge_weight)\n","        graph.edata['norm_weight'] = norm_edge_weight\n","\n","    node_features_test = graph.ndata['feature']\n","    edge_features_test = graph.edata['h']\n","    \n","    with th.no_grad():\n","        test_pred = model.trained_model(graph, node_features_test, edge_features_test)\n","        \n","    elapsed = timeit.default_timer() - start_time\n","\n","    loss = loss_fn(test_pred, actual_labels)\n","    \n","    test_pred = test_pred.argmax(1)\n","    test_pred = th.Tensor.cpu(test_pred).detach().numpy()\n","\n","    if multi_class:\n","        actual = np.vectorize(labels_names[0].get)(actual_labels)\n","        test_pred = np.vectorize(labels_names[0].get)(test_pred)\n","    else:\n","        actual = [\"Normal\" if i == 0 else \"Attack\" for i in actual_labels]\n","        test_pred = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred]\n","\n","    cr = classification_report(actual, test_pred, digits=4, output_dict=True, zero_division=0)\n","    cm = confusion_matrix(actual, test_pred, labels=_labels)\n","    results_fpr_fnr = calculate_FPR_FNR_with_global(cm)\n","    \n","    val_acc = cr[\"accuracy\"] * 100\n","    val_loss = loss.item()\n","    results_f[\"val_accuracy\"][model.model_name].append(val_acc)\n","    results_f[\"val_loss\"][model.model_name].append(val_loss)\n","    results_f[\"val_precision\"][model.model_name].append(cr['weighted avg']['precision'] * 100)\n","    results_f[\"val_recall\"][model.model_name].append(cr['weighted avg']['recall'] * 100)\n","    results_f[\"val_f1\"][model.model_name].append(cr['weighted avg']['f1-score'] * 100)\n","    results_f[\"val_FPR\"][model.model_name].append(results_fpr_fnr[\"global\"][\"FPR\"])\n","    results_f[\"val_FNR\"][model.model_name].append(results_fpr_fnr[\"global\"][\"FNR\"])\n","    \n","    return (val_acc, val_loss, elapsed)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["def train_model(model: models.Model, graph, _labels):\n","    node_features = graph.ndata['h']\n","    edge_features = graph.edata['h']\n","\n","    edge_label = graph.edata[dataset.class_num_col if multi_class else dataset.label_col]\n","        \n","    train_mask = graph.edata['train_mask']\n","\n","    # model = EGRAPHSAGE(num_features, num_features, 128, F.relu,\n","    #                    dropout=0.2, num_neighbors=4, residual=residual)\n","\n","    if model.norm:\n","        edge_weight = th.ones(graph.num_edges(), dtype=th.float32)\n","        norm = EdgeWeightNorm(norm='both')\n","        norm_edge_weight = norm(graph, edge_weight)\n","        graph.edata['norm_weight'] = norm_edge_weight\n","\n","    if model.model_class == models.EGRAPHSAGE:\n","        model.trained_model = model.model_class(ndim_in, num_features, model.ndim_out, num_layers=model.num_layers, activation=model.activation, aggregation=model.aggregation,\n","                            dropout=model.dropout, num_neighbors=model.num_neighbors, residual=model.residual, num_class=num_classes)\n","        model.best_model = model.model_class(ndim_in, num_features, model.ndim_out, num_layers=model.num_layers, activation=model.activation, aggregation=model.aggregation,\n","                            dropout=model.dropout, num_neighbors=model.num_neighbors, residual=model.residual, num_class=num_classes)  \n","    elif model.model_class == models.EGCN:\n","        model.trained_model = model.model_class(ndim_in, num_features, model.ndim_out, num_layers=model.num_layers, activation=model.activation,\n","                            dropout=model.dropout, residual=model.residual, num_class=num_classes, norm=model.norm)\n","        model.best_model = model.model_class(ndim_in, num_features, model.ndim_out, num_layers=model.num_layers, activation=model.activation,\n","                            dropout=model.dropout, residual=model.residual, num_class=num_classes, norm=model.norm)\n","    else:\n","        model.trained_model = model.model_class(ndim_in, num_features, model.ndim_out, num_layers=model.num_layers, activation=model.activation,\n","                            dropout=model.dropout, residual=model.residual, num_class=num_classes)\n","        model.best_model = model.model_class(ndim_in, num_features, model.ndim_out, num_layers=model.num_layers, activation=model.activation,\n","                            dropout=model.dropout, residual=model.residual, num_class=num_classes)\n","\n","    opt = th.optim.Adam(model.trained_model.parameters(), lr = learning_rate, weight_decay=LAMBD_2)\n","    \n","    best_acc = 0\n","    for epoch in range(1, num_epochs):\n","        model.trained_model.train()\n","        pred = model.trained_model(graph, node_features, edge_features[train_mask])\n","        loss = criterion(pred[train_mask], edge_label[train_mask])\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","        if epoch == 1:\n","            print(\"================================\")\n","            print(\"================================\")\n","            print(f\"Training Model: {model.model_name}\")\n","            print(f\"Edge label shape: {edge_label.shape}\")\n","            print(f\"Edge label unique values: {th.unique(edge_label)}\")\n","            print(f\"Pred shape: {pred.shape}\")\n","            \n","        train_acc = compute_accuracy(pred[train_mask], edge_label[train_mask]) * 100\n","        print(f\"Model: {model.model_name} -- Epoch: {epoch} -- Training acc: {train_acc:.2f} -- Training loss: {loss.item():.4f}\")\n","        \n","        results_final[\"train_accuracy\"][model.model_name].append(train_acc)\n","        results_final[\"train_loss\"][model.model_name].append(loss.item())\n","        \n","        val_acc, val_loss, elapsed = evaluate_model(model, G_val, val_labels, criterion, results_final, _labels)\n","\n","        print(f\"Model: {model.model_name} -- Epoch: {epoch} -- Validation acc: {val_acc:.2f} -- Validation loss: {val_loss:.4f}\")\n","        print(\"Time for validation: \", str(elapsed) + ' seconds')    \n","        \n","        if best_acc < val_acc:\n","            best_acc = val_acc\n","            best_model_state = model.trained_model.state_dict().copy()\n","            # th.save(best_model_state, f\"temp/best_model_{model.model_name}.pth\")\n","            th.save(model.trained_model, f\"temp/best_model_{model.model_name}.pth\")\n","            \n","    model.best_model.load_state_dict(best_model_state)\n","        \n","    return model"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def test_model(model:models.Model, graph, actual_labels, results_f, _labels):\n","    print(\"=======================\")\n","    print(f\"testing model: {model.model_name}\")\n","    \n","    start_time = timeit.default_timer()\n","    model.best_model.eval()\n","    \n","    if model.norm:\n","        edge_weight = th.ones(graph.num_edges(), dtype=th.float32)\n","        norm = EdgeWeightNorm(norm='both')\n","        norm_edge_weight = norm(graph, edge_weight)\n","        graph.edata['norm_weight'] = norm_edge_weight\n","    \n","    node_features_test = graph.ndata['feature']\n","    edge_features_test = graph.edata['h']\n","    \n","    with th.no_grad():\n","        test_pred = model.best_model(graph, node_features_test, edge_features_test)\n","        \n","    elapsed = timeit.default_timer() - start_time\n","    \n","    test_pred = test_pred.argmax(1)\n","    test_pred = th.Tensor.cpu(test_pred).detach().numpy()\n","    \n","    if multi_class:\n","        actual = np.vectorize(labels_names[0].get)(actual_labels)\n","        test_pred = np.vectorize(labels_names[0].get)(test_pred)\n","    else:\n","        actual = [\"Normal\" if i == 0 else \"Attack\" for i in actual_labels]\n","        test_pred = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred]\n","\n","    cr = classification_report(actual, test_pred, digits=4, output_dict=True, zero_division=0)\n","    cm = confusion_matrix(actual, test_pred, labels=_labels)\n","    cm_normalized = confusion_matrix(actual, test_pred, labels=labels, normalize=\"true\")\n","    results_fpr_fnr = calculate_FPR_FNR_with_global(cm)\n","\n","    # Log metrics\n","    results_f[model.model_name][\"elapsed\"] = elapsed\n","    results_f[model.model_name][\"classification_report\"] = cr\n","    results_f[model.model_name][\"results_fpr_fnr\"] = results_fpr_fnr\n","    results_f[\"accuracy\"][model.model_name] = cr[\"accuracy\"] * 100\n","    results_f[\"f1_score\"][model.model_name] = cr['weighted avg']['f1-score'] * 100\n","    results_f[\"FPR\"][model.model_name] = results_fpr_fnr[\"global\"][\"FPR\"]\n","    results_f[\"FNR\"][model.model_name] = results_fpr_fnr[\"global\"][\"FNR\"]\n","    results_f[\"time_elapsed\"][model.model_name] = elapsed\n","\n","    print(classification_report(actual, test_pred, digits=4, zero_division=0))\n","    \n","    return actual, test_pred, cm, cm_normalized\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Training GNN models"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["%autoreload"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["for m in my_models:\n","    train_model(m, G, labels)\n","    actual, test_pred, cm, cm_normalized = test_model(m, G_test, test_labels, results_final, labels)\n","    plot_confusion_matrix(cm=cm,\n","                          normalize=False,\n","                          target_names=labels,\n","                          title=f\"Confusion Matrix of {m.model_name}\",\n","                          file_path=f\"{confusion_matrices_path}/{m.model_name}.png\")\n","    \n","    plot_confusion_matrix(cm=cm_normalized,\n","                          normalize=False,\n","                          normalized=True,\n","                          target_names=labels,\n","                          title=f\"Normalized Confusion Matrix of {m.model_name}\",\n","                          file_path=f\"{confusion_matrices_path}/{m.model_name}_normalized.png\")\n","    \n","    with open(os.path.join(folder_path, \"actual.json\"), \"w\") as f:\n","        f.writelines(json.dumps(actual, cls=NumpyEncoder))\n","        \n","    with open(os.path.join(folder_path, f\"{m.model_name}_pred.json\"), \"w\") as f:\n","        f.writelines(json.dumps(test_pred, cls=NumpyEncoder))\n","        \n","    with open(os.path.join(folder_path, \"results.json\"), \"w\") as f:\n","        f.writelines(json.dumps(results_final, cls=NumpyEncoder))"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["\n","# import importlib.util\n","# import sys"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# def add_lib(module_name, path):\n","#     spec = importlib.util.spec_from_file_location(module_name, path)\n","#     dataset_info = importlib.util.module_from_spec(spec)\n","#     sys.modules[module_name] = dataset_info\n","#     spec.loader.exec_module(dataset_info)\n","\n","# add_lib(\"e_gat\", \"C:/Users/Administrateur/Desktop/GNN-NIDS/src/models/e_gat_my_code.py\")\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Administrateur\\AppData\\Local\\Temp\\3\\ipykernel_20772\\2443819201.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  m.best_model = th.load(f\"temp/best_model_{m.model_name}.pth\")\n"]},{"name":"stdout","output_type":"stream","text":["temp/best_model_e_gat_res.pth\n","=======================\n","testing model: e_gat_res\n"]},{"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (535059x74 and 64x1)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m m\u001b[39m.\u001b[39mbest_model \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtemp/best_model_\u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtemp/best_model_\u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m actual, test_pred, cm, cm_normalized \u001b[39m=\u001b[39m test_model(m, G_test, test_labels, results_final, labels)\n\u001b[0;32m      6\u001b[0m plot_confusion_matrix(cm\u001b[39m=\u001b[39mcm,\n\u001b[0;32m      7\u001b[0m                       normalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m                       target_names\u001b[39m=\u001b[39mlabels,\n\u001b[0;32m      9\u001b[0m                       title\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix of \u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m                       file_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mconfusion_matrices_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m plot_confusion_matrix(cm\u001b[39m=\u001b[39mcm_normalized,\n\u001b[0;32m     13\u001b[0m                       normalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m                       normalized\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m                       target_names\u001b[39m=\u001b[39mlabels,\n\u001b[0;32m     16\u001b[0m                       title\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNormalized Confusion Matrix of \u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m                       file_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mconfusion_matrices_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_normalized.png\u001b[39m\u001b[39m\"\u001b[39m)\n","Cell \u001b[1;32mIn[28], line 18\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(model, graph, actual_labels, results_f, _labels)\u001b[0m\n\u001b[0;32m     15\u001b[0m edge_features_test \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39medata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 18\u001b[0m     test_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mbest_model(graph, node_features_test, edge_features_test)\n\u001b[0;32m     20\u001b[0m elapsed \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m     22\u001b[0m test_pred \u001b[39m=\u001b[39m test_pred\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mC:/Users/Administrateur/Desktop/GNN-NIDS/src/models/e_gat_my_code.py:177\u001b[0m, in \u001b[0;36mEGAT.forward\u001b[1;34m(self, g, nfeats, efeats)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, g, nfeats, efeats):\n\u001b[1;32m--> 177\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgnn(g, nfeats, efeats)\n\u001b[0;32m    178\u001b[0m     \u001b[39m# print(\"DONE\")\u001b[39;00m\n\u001b[0;32m    179\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred(g, h)\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mC:/Users/Administrateur/Desktop/GNN-NIDS/src/models/e_gat_my_code.py:132\u001b[0m, in \u001b[0;36mGAT.forward\u001b[1;34m(self, g, nfeats, efeats)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    131\u001b[0m         nfeats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(nfeats)\n\u001b[1;32m--> 132\u001b[0m     nfeats \u001b[39m=\u001b[39m layer(g, nfeats, efeats)\n\u001b[0;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m nfeats\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mC:/Users/Administrateur/Desktop/GNN-NIDS/src/models/e_gat_my_code.py:82\u001b[0m, in \u001b[0;36mGATLayer.forward\u001b[1;34m(self, g, nfeats, efeats)\u001b[0m\n\u001b[0;32m     78\u001b[0m    g\u001b[39m.\u001b[39medata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m efeats\n\u001b[0;32m     79\u001b[0m  \u001b[39m#  print(\"OK1\")\u001b[39;00m\n\u001b[0;32m     80\u001b[0m    \u001b[39m# equation (2)\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m    g\u001b[39m.\u001b[39;49mapply_edges(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_attention)\n\u001b[0;32m     83\u001b[0m \u001b[39m#   print(\"OK2\")\u001b[39;00m\n\u001b[0;32m     84\u001b[0m    \u001b[39m# equation (3) & (4)\u001b[39;00m\n\u001b[0;32m     85\u001b[0m    \u001b[39m# self.g.update_all(self.message_func, self.reduce_func)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m    g\u001b[39m.\u001b[39mupdate_all(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage_func, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduce_func)\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\dgl\\heterograph.py:4700\u001b[0m, in \u001b[0;36mDGLGraph.apply_edges\u001b[1;34m(self, func, edges, etype)\u001b[0m\n\u001b[0;32m   4698\u001b[0m     edata \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39minvoke_gsddmm(g, func)\n\u001b[0;32m   4699\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4700\u001b[0m     edata \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49minvoke_edge_udf(g, eid, etype, func)\n\u001b[0;32m   4702\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mnumber_of_etypes() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m etype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4703\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_e_repr(etid, eid, edata)\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\dgl\\core.py:96\u001b[0m, in \u001b[0;36minvoke_edge_udf\u001b[1;34m(graph, eid, etype, func, orig_eid)\u001b[0m\n\u001b[0;32m     87\u001b[0m dstdata \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39m_node_frames[dtid]\u001b[39m.\u001b[39msubframe(v)\n\u001b[0;32m     88\u001b[0m ebatch \u001b[39m=\u001b[39m EdgeBatch(\n\u001b[0;32m     89\u001b[0m     graph,\n\u001b[0;32m     90\u001b[0m     eid \u001b[39mif\u001b[39;00m orig_eid \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m orig_eid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m     dstdata,\n\u001b[0;32m     95\u001b[0m )\n\u001b[1;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m func(ebatch)\n","File \u001b[1;32mC:/Users/Administrateur/Desktop/GNN-NIDS/src/models/e_gat_my_code.py:33\u001b[0m, in \u001b[0;36mGATLayer.edge_attention\u001b[1;34m(self, edges)\u001b[0m\n\u001b[0;32m     30\u001b[0m z2 \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mcat([edges\u001b[39m.\u001b[39msrc[\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m], edges\u001b[39m.\u001b[39mdst[\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m]], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[39m# print(\"OKedge1\")\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m# print(z2.shape)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn_fc(z2)\n\u001b[0;32m     34\u001b[0m \u001b[39m# print(\"OKedge2\")\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m# print(f'attention={F.leaky_relu(a)}')\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39me\u001b[39m\u001b[39m\"\u001b[39m: F\u001b[39m.\u001b[39mleaky_relu(a)}\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\GNN-NIDS\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n","\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (535059x74 and 64x1)"]}],"source":["# for m in my_models:\n","#     m.best_model = th.load(f\"temp/best_model_{m.model_name}.pth\")\n","#     print(f\"temp/best_model_{m.model_name}.pth\")\n","    \n","#     actual, test_pred, cm, cm_normalized = test_model(m, G_test, test_labels, results_final, labels)\n","#     plot_confusion_matrix(cm=cm,\n","#                           normalize=False,\n","#                           target_names=labels,\n","#                           title=f\"Confusion Matrix of {m.model_name}\",\n","#                           file_path=f\"{confusion_matrices_path}/{m.model_name}.png\")\n","    \n","#     plot_confusion_matrix(cm=cm_normalized,\n","#                           normalize=False,\n","#                           normalized=True,\n","#                           target_names=labels,\n","#                           title=f\"Normalized Confusion Matrix of {m.model_name}\",\n","#                           file_path=f\"{confusion_matrices_path}/{m.model_name}_normalized.png\")\n","    \n","#     with open(os.path.join(folder_path, \"actual.json\"), \"w\") as f:\n","#         f.writelines(json.dumps(actual, cls=NumpyEncoder))\n","        \n","#     with open(os.path.join(folder_path, f\"{m.model_name}_pred.json\"), \"w\") as f:\n","#         f.writelines(json.dumps(test_pred, cls=NumpyEncoder))\n","        \n","#     with open(os.path.join(folder_path, \"results.json\"), \"w\") as f:\n","#         f.writelines(json.dumps(results_final, cls=NumpyEncoder))"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4775518,"sourceId":8089266,"sourceType":"datasetVersion"},{"datasetId":4775527,"sourceId":8089281,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
