{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-24T12:01:21.407444Z","iopub.status.busy":"2024-08-24T12:01:21.407010Z","iopub.status.idle":"2024-08-24T12:01:29.827271Z","shell.execute_reply":"2024-08-24T12:01:29.826059Z","shell.execute_reply.started":"2024-08-24T12:01:21.407404Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import os\n","import pickle\n","\n","import networkx as nx\n","\n","from src.dataset.dataset_info import datasets"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# name = \"cic_ton_iot_5_percent\"\n","# name = \"cic_ton_iot\"\n","# name = \"cic_ids_2017_5_percent\"\n","# name = \"cic_ids_2017\"\n","# name = \"cic_bot_iot\"\n","# name = \"cic_ton_iot_modified\"\n","# name = \"nf_ton_iotv2_modified\"\n","# name = \"ccd_inid_modified\"\n","# name = \"nf_uq_nids_modified\"\n","# name = \"edge_iiot\"\n","# name = \"nf_cse_cic_ids2018\"\n","# name = \"nf_bot_iotv2\"\n","name = \"nf_uq_nids\"\n","# name = \"x_iiot\"\n","\n","dataset = datasets[name]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import networkx as nx\n","import igraph as ig\n","import json\n","import timeit\n","\n","import time\n","from functools import wraps\n","\n","\n","def time_execution(func):\n","    @wraps(func)\n","    def wrapper(*args, **kwargs):\n","        # Check if verbose is in kwargs, defaulting to False if not provided\n","        verbose = kwargs.get(\"verbose\", False)\n","        if not verbose:\n","            start_time = timeit.default_timer()\n","            result = func(*args, **kwargs)\n","            print(\n","                f\"==>> {func.__name__}: {result}, in {str(timeit.default_timer() - start_time)} seconds\")\n","        else:\n","            result = func(*args, **kwargs)\n","        return result\n","    return wrapper\n","\n","\n","@time_execution\n","def number_of_nodes(G, verbose):\n","    return G.number_of_nodes()\n","\n","\n","@time_execution\n","def number_of_edges(G, verbose):\n","    return G.number_of_edges()\n","\n","\n","@time_execution\n","def transitivity(G, verbose):\n","    return nx.transitivity(G)\n","\n","\n","@time_execution\n","def density(G, verbose):\n","    return nx.density(G)\n","\n","\n","@time_execution\n","def mixing_parameter(G, communities, verbose):\n","\n","    # Step 1: Map each node to its community\n","    node_to_community = {}\n","    for community_index, community in enumerate(communities):\n","        for node in community:\n","            node_to_community[node] = community_index\n","\n","    # Step 2: Count inter-cluster edges efficiently\n","    inter_cluster_edges = 0\n","    for u, v in G.edges():\n","        # Directly check if u and v belong to different communities\n","        if node_to_community[u] != node_to_community[v]:\n","            inter_cluster_edges += 1\n","\n","    mixing_parameter = inter_cluster_edges / G.number_of_edges()\n","\n","    return mixing_parameter\n","\n","\n","@time_execution\n","def modularity(G, communities, verbose):\n","\n","    start_time = timeit.default_timer()\n","    modularity = nx.community.modularity(G, communities)\n","    if verbose:\n","        print(\n","            f\"==>> modularity: {modularity}, in {str(timeit.default_timer() - start_time)} seconds\")\n","\n","    return modularity\n","\n","\n","def get_degrees(G, verbose):\n","    start_time = timeit.default_timer()\n","    degrees = [degree for _, degree in G.degree()]\n","    if verbose:\n","        print(\n","            f\"==>> calculated degrees, in {str(timeit.default_timer() - start_time)} seconds\")\n","    return degrees\n","\n","\n","def find_communities(G, verbose):\n","\n","    start_time = timeit.default_timer()\n","    G1 = ig.Graph.from_networkx(G)\n","\n","    part = G1.community_infomap()\n","    # part = G1.community_multilevel()\n","    # part = G1.community_spinglass()\n","    # part = G1.community_edge_betweenness()\n","\n","    communities = []\n","    for com in part:\n","        communities.append([G1.vs[node_index]['_nx_name']\n","                           for node_index in com])\n","\n","    # communities = nx.community.louvain_communities(G)\n","    if verbose:\n","        print(\n","            f\"==>> number_of_communities: {len(communities)}, in {str(timeit.default_timer() - start_time)} seconds\")\n","\n","    return communities\n","\n","\n","def calculate_graph_measures(G, file_path=None, verbose=False):\n","\n","    properties = {}\n","\n","    properties[\"number_of_nodes\"] = number_of_nodes(G, verbose)\n","    properties[\"number_of_edges\"] = number_of_edges(G, verbose)\n","\n","    degrees = get_degrees(G, verbose)\n","\n","    properties[\"max_degree\"] = max(degrees)\n","    properties[\"avg_degree\"] = sum(degrees) / len(degrees)\n","\n","    if type(G) == nx.DiGraph or type(G) == nx.Graph:\n","        properties[\"transitivity\"] = transitivity(G, verbose)\n","\n","    properties[\"density\"] = density(G, verbose)\n","\n","    communities = find_communities(G, verbose)\n","\n","    properties[\"number_of_communities\"] = len(communities)\n","    properties[\"mixing_parameter\"] = mixing_parameter(G, communities, verbose)\n","    properties[\"modularity\"] = modularity(G, communities, verbose)\n","\n","    if file_path:\n","        outfile = open(file_path, 'w')\n","        outfile.writelines(json.dumps(properties))\n","        outfile.close()\n","\n","    return properties\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["==>> number_of_nodes: 93645, in 6.299465894699097e-06 seconds\n","==>> number_of_edges: 10729039, in 0.429551899433136 seconds\n","==>> calculated degrees, in 0.6344597004354 seconds\n","==>> density: 0.001223478307607757, in 0.9582200013101101 seconds\n"]}],"source":["# with open(\"datasets/\" + name + \"/training_graph.pkl\", \"rb\") as f:\n","#     G = pickle.load(f)\n","df = pd.read_parquet(dataset.path)\n","G = nx.from_pandas_edgelist(df, dataset.src_ip_col, dataset.dst_ip_col, create_using=nx.MultiDiGraph())\n","\n","\n","# get netowrk properties\n","graph_measures = calculate_graph_measures(G, \"datasets/\" + name + \"/multiDiGraph_graph_measures.json\", verbose=True)\n","print(f\"==>> graph_measures: {graph_measures}\")\n","\n","graph_measures = calculate_graph_measures(nx.DiGraph(G), \"datasets/\" + name + \"/digraph_graph_measures.json\", verbose=True)\n","print(f\"==>> graph_measures: {graph_measures}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["==>> number_of_nodes: 268120, in 5.599111318588257e-06 seconds\n","==>> number_of_edges: 631814, in 0.8301995992660522 seconds\n","==>> calculated degrees, in 0.9263340011239052 seconds\n","==>> density: 8.788857910562231e-06, in 0.5778869986534119 seconds\n","==>> number_of_communities: 42, in 830.590715598315 seconds\n","==>> mixing_parameter: 0.0, in 1.8683775998651981 seconds\n","==>> modularity: 0.25005780477671435, in 5.020574200898409 seconds\n","==>> modularity: 0.25005780477671435, in 5.0207654014229774 seconds\n","==>> graph_measures: {'number_of_nodes': 268120, 'number_of_edges': 631814, 'max_degree': 147700, 'avg_degree': 4.71291958824407, 'density': 8.788857910562231e-06, 'number_of_communities': 42, 'mixing_parameter': 0.0, 'modularity': 0.25005780477671435}\n","==>> number_of_nodes: 268120, in 9.3020498752594e-06 seconds\n","==>> number_of_edges: 364616, in 0.5279907993972301 seconds\n","==>> calculated degrees, in 0.1259106993675232 seconds\n","==>> transitivity: 9.713003170921958e-07, in 1.8788352981209755 seconds\n","==>> density: 5.071996213945177e-06, in 0.1333415023982525 seconds\n","==>> number_of_communities: 2017, in 383.9224935993552 seconds\n","==>> mixing_parameter: 0.18721065449678567, in 1.0269913002848625 seconds\n","==>> modularity: 0.6991267371403524, in 3.397045399993658 seconds\n","==>> modularity: 0.6991267371403524, in 3.397280301898718 seconds\n","==>> graph_measures: {'number_of_nodes': 268120, 'number_of_edges': 364616, 'max_degree': 69243, 'avg_degree': 2.719797105773534, 'transitivity': 9.713003170921958e-07, 'density': 5.071996213945177e-06, 'number_of_communities': 2017, 'mixing_parameter': 0.18721065449678567, 'modularity': 0.6991267371403524}\n"]}],"source":["df[dataset.src_port_col] = df[dataset.src_port_col].astype(float).astype(int).astype(str) # to remove the decimal point\n","df[dataset.src_ip_col] = df[dataset.src_ip_col] + ':' + df[dataset.src_port_col]\n","\n","df[dataset.dst_port_col] = df[dataset.dst_port_col].astype(float).astype(int).astype(str) # to remove the decimal point\n","df[dataset.dst_ip_col] = df[dataset.dst_ip_col] + ':' + df[dataset.dst_port_col]\n","\n","G = nx.from_pandas_edgelist(df, dataset.src_ip_col, dataset.dst_ip_col, create_using=nx.MultiDiGraph())\n","\n","\n","# get netowrk properties\n","graph_measures = calculate_graph_measures(G, \"datasets/\" + name + \"/ports_multiDiGraph_graph_measures.json\", verbose=True)\n","print(f\"==>> graph_measures: {graph_measures}\")\n","\n","graph_measures = calculate_graph_measures(nx.DiGraph(G), \"datasets/\" + name + \"/ports_digraph_graph_measures.json\", verbose=True)\n","print(f\"==>> graph_measures: {graph_measures}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:01:38.979760Z","iopub.status.busy":"2024-08-24T12:01:38.979252Z","iopub.status.idle":"2024-08-24T12:01:39.036289Z","shell.execute_reply":"2024-08-24T12:01:39.035076Z","shell.execute_reply.started":"2024-08-24T12:01:38.979720Z"},"trusted":true},"outputs":[],"source":["# with open(\"datasets/\" + name + \"/training_graph.pkl\", \"rb\") as f:\n","#     G = pickle.load(f)\n","\n","\n","# # get netowrk properties\n","# graph_measures = calculate_graph_measures(G, \"datasets/\" + name + \"/training_graph_measures.json\", verbose=True)\n","# print(f\"==>> graph_measures: {graph_measures}\")\n","\n","# graph_measures = calculate_graph_measures(nx.DiGraph(G), \"datasets/\" + name + \"/training_graph_simple_measures.json\", verbose=True)\n","# print(f\"==>> graph_measures: {graph_measures}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# with open(\"datasets/\" + name + \"/testing_graph.pkl\", \"rb\") as f:\n","#     G_test = pickle.load(f)\n","\n","# graph_measures = calculate_graph_measures(G_test, \"datasets/\" + name + \"/testing_graph_measures.json\", verbose=True)\n","# print(f\"==>> graph_measures: {graph_measures}\")\n","\n","# graph_measures = calculate_graph_measures(nx.DiGraph(G_test), \"datasets/\" + name + \"/testing_graph_simple_measures.json\", verbose=True)\n","# print(f\"==>> graph_measures: {graph_measures}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import igraph as ig\n","# G1 = ig.Graph.from_networkx(G)\n","\n","# part = G1.community_infomap()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import networkx as nx\n","\n","# import timeit\n","\n","# verbose = True\n","# properties = {}\n","\n","# start_time = timeit.default_timer()\n","\n","# # part = G1.community_multilevel()\n","# # part = G1.community_spinglass()\n","# # part = G1.community_edge_betweenness()\n","\n","# communities = []\n","# for com in part:\n","#     communities.append([G1.vs[node_index]['_nx_name']\n","#                         for node_index in com])\n","\n","# # communities = nx.community.louvain_communities(G)\n","# number_of_communities = len(communities)\n","# if verbose:\n","#     print(\n","#         f\"==>> number_of_communities: {number_of_communities}, in {str(timeit.default_timer() - start_time)} seconds\")\n","# properties[\"number_of_communities\"] = number_of_communities\n","\n","# # Step 1: Map each node to its community\n","# node_to_community = {}\n","# for community_index, community in enumerate(communities):\n","#     for node in community:\n","#         node_to_community[node] = community_index\n","\n","# # Step 2: Count inter-cluster edges efficiently\n","# inter_cluster_edges = 0\n","# for u, v in G.edges():\n","#     # Directly check if u and v belong to different communities\n","#     if node_to_community[u] != node_to_community[v]:\n","#         inter_cluster_edges += 1\n","\n","# start_time = timeit.default_timer()\n","# mixing_parameter = inter_cluster_edges / G.number_of_edges()\n","# if verbose:\n","#     print(\n","#         f\"==>> mixing_parameter: {mixing_parameter}, in {str(timeit.default_timer() - start_time)} seconds\")\n","# properties[\"mixing_parameter\"] = mixing_parameter\n","\n","# start_time = timeit.default_timer()\n","# modularity = nx.community.modularity(G, communities)\n","# if verbose:\n","#     print(\n","#         f\"==>> modularity: {modularity}, in {str(timeit.default_timer() - start_time)} seconds\")\n","# properties[\"modularity\"] = modularity"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4775518,"sourceId":8089266,"sourceType":"datasetVersion"},{"datasetId":4775527,"sourceId":8089281,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
